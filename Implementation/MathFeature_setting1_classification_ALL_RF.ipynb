{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# import xgboost as xgb\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bbced7669aac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all experiment parameters\n",
    "##################################################################################\n",
    "\n",
    "expName = \"MathFeature_setting1\"\n",
    "outPath = \"Generated\"\n",
    "\n",
    "dataset_path = \"Datasets\"\n",
    "setting = \"Setting1\"\n",
    "output_path = \"Results_ALL-v2\"\n",
    "\n",
    "datafile_extensions = \".csv\"\n",
    "\n",
    "modelNames = [\"RandomForest\"]\n",
    "\n",
    "shuffle = False\n",
    "seed = None\n",
    "\n",
    "reject_encoding_list = [\"NM-complex\", \"kmer\", \"kstep\", \"rckmer\", \"ALL\"]\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "kernel_length = 5\n",
    "\n",
    "##################################################################################\n",
    "##### Define the modelling hyperparameters\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Checking the directory\n",
    "##################################################################################\n",
    "\n",
    "dataset_setting_path = os.path.join(outPath, expName, dataset_path, setting)\n",
    "dataset_varieties = next(os.walk(dataset_setting_path))\n",
    "result_output_path = os.path.join(outPath, expName, output_path, setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation by joining from all encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_variety in dataset_varieties[1]:\n",
    "#     current_dataset_variety_path = os.path.join(dataset_setting_path, dataset_variety)\n",
    "    \n",
    "    \n",
    "#     print(\"\\nProcessing variety: \", dataset_variety)\n",
    "#     print(\"======================================\")\n",
    "    \n",
    "#     i = 0\n",
    "    \n",
    "#     for root, dirs, files in os.walk(current_dataset_variety_path):\n",
    "#         for file in files:\n",
    "#             if os.path.splitext(file)[-1] == datafile_extensions:\n",
    "                \n",
    "#                 encoding_type = file.split(\".\")[0].split(\"_\")[-1]\n",
    "                \n",
    "#                 if encoding_type not in reject_encoding_list:\n",
    "                \n",
    "#                     input_file_full_path = os.path.join(root, file)\n",
    "\n",
    "#                     ## check if input file has header\n",
    "#                     file_obj = open(input_file_full_path, \"r\")\n",
    "#                     first_line = file_obj.readline()\n",
    "#                     file_obj.close()\n",
    "#                     file_has_header = None\n",
    "#                     if first_line.split(\",\")[0] == \"nameseq\" or first_line.replace(\"\\n\", \"\").split(\",\")[-1] == \"label\":\n",
    "#                         file_has_header = 0\n",
    "\n",
    "#                     sequences_df = pd.read_csv(input_file_full_path, header = file_has_header)\n",
    "                    \n",
    "#                     ## adding encoding type to header names\n",
    "#                     cols = list(sequences_df.columns)\n",
    "#                     cols = [encoding_type+\"_\"+str(col) for col in cols]\n",
    "#                     sequences_df.columns = cols\n",
    "                    \n",
    "#                     # sequences_df = pd.read_csv(input_file_full_path, header = \"infer\")\n",
    "#                     # print(\"Encoding completed adding: \", encoding_type)\n",
    "#                     # print(\"Columns: \", sequences_df.columns)\n",
    "                    \n",
    "#                     sequences_df = sequences_df.rename(columns = {sequences_df.columns[0] : 'nameseq', \n",
    "#                                                                   sequences_df.columns[-1] : 'label'})\n",
    "                    \n",
    "#                     sequences_df = sequences_df.drop(\"label\", axis = 1)\n",
    "                    \n",
    "#                     if i == 0:\n",
    "#                         variety_dataset_df = sequences_df\n",
    "                        \n",
    "#                     else:\n",
    "#                         # variety_dataset_df = pd.concat([variety_dataset_df, sequences_df], \n",
    "#                         #                                join=\"inner\", \n",
    "#                         #                                keys = (\"nameseq\"), \n",
    "#                         #                                ignore_index = True, \n",
    "#                         #                                axis = 1)\n",
    "#                         # variety_dataset_df = variety_dataset_df.rename(columns = {0 : 'nameseq'})\n",
    "                        \n",
    "#                         variety_dataset_df = pd.merge(variety_dataset_df, sequences_df, \n",
    "#                                                       left_on='nameseq', right_on='nameseq', \n",
    "#                                                       how='inner')\n",
    "                    \n",
    "#                     print(\"Encoding completed adding: \", encoding_type)\n",
    "                    \n",
    "#                     i = i+1\n",
    "                    \n",
    "#     file_name = \"_\".join(file.split(\".\")[0].split(\"_\")[0:-1]+[\"ALL\"])+\".\"+file.split(\".\")[1]\n",
    "#     variety_dataset_df.to_csv(os.path.join(root, file_name), \n",
    "#                               header = True, \n",
    "#                               index = False)\n",
    "    \n",
    "#     print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan/Infinity correction - dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root, dirs, files in os.walk(dataset_setting_path):\n",
    "#     for file in files:\n",
    "#         if (os.path.splitext(file)[-1] == datafile_extensions) & (file.split(\".\")[0].split(\"_\")[-1] == \"ALL\"):\n",
    "            \n",
    "#             input_file_full_path = os.path.join(root, file)\n",
    "            \n",
    "#             print(\" Processing file : \",input_file_full_path)\n",
    "            \n",
    "#             sequences_df = pd.read_csv(input_file_full_path, header = \"infer\", low_memory=False)\n",
    "            \n",
    "#             vals = sequences_df.drop(\"nameseq\", axis = 1).values.astype(np.float)\n",
    "#             sequences_df_columns = sequences_df.drop(\"nameseq\", axis = 1).columns\n",
    "\n",
    "#             if np.isnan(np.max(vals)):\n",
    "#                 nans = np.argwhere(np.isnan(vals.astype(np.float)))\n",
    "#                 vals = np.delete(vals, np.unique(nans[:,1]), axis=1)\n",
    "#                 drop_cols = sequences_df_columns[np.unique(nans[:,1])]\n",
    "#                 for drop_col in drop_cols:\n",
    "#                     sequences_df = sequences_df.drop(drop_col, axis = 1)\n",
    "\n",
    "#             sequences_df_columns = sequences_df.drop(\"nameseq\", axis = 1).columns\n",
    "\n",
    "#             if np.max(vals)>1e+308:\n",
    "#                 vals = np.where(vals == np.max(vals), \n",
    "#                                 None, \n",
    "#                                 vals)\n",
    "#                 nans = np.argwhere(np.isnan(vals.astype(np.float)))\n",
    "#                 vals = np.delete(vals, np.unique(nans[:,1]), axis=1)\n",
    "#                 drop_cols = sequences_df_columns[np.unique(nans[:,1])]\n",
    "#                 for drop_col in drop_cols:\n",
    "#                     sequences_df = sequences_df.drop(drop_col, axis = 1)\n",
    "                    \n",
    "#             sequences_df.to_csv(input_file_full_path.replace(\"_ALL\", \"_ALL-v2\"), \n",
    "#                                 header = True, \n",
    "#                                 index = False)\n",
    "            \n",
    "#             print(\" Generated file : \",input_file_full_path.replace(\"_ALL\", \"_ALL-v2\"))\n",
    "#             print(\"\\n################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "error_list = []\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Encoding_Type\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_setting_path):\n",
    "    for file in files:\n",
    "        if (os.path.splitext(file)[-1] == datafile_extensions) & (file.split(\".\")[0].split(\"_\")[-1] == \"ALL-v2\"):\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "                encoding_type = file.split(\".\")[0].split(\"_\")[-1]\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### read the current file\n",
    "                ##################################################################################\n",
    "\n",
    "                input_file_full_path = os.path.join(root, file)\n",
    "                sequences_df = pd.read_csv(input_file_full_path, header = \"infer\", low_memory=False)\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### extract data from the current dataframe file\n",
    "                ##################################################################################\n",
    "\n",
    "                sequences_df[\"class\"] = np.where(sequences_df[sequences_df.columns[0]].str.contains(\"nucleosomal\"), 1, 0)\n",
    "\n",
    "                print(\"\\n======================================================================\")\n",
    "                print(\"\\nFile: \"+os.path.join(root, file))\n",
    "                print(\"Nucleosomi: \"+str(sum(sequences_df[\"class\"])))\n",
    "                print(\"Linker: \"+str(len(sequences_df) - sum(sequences_df[\"class\"])))\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### Generate Folds from dataset, and store to file\n",
    "                ##################################################################################\n",
    "\n",
    "                ## create the features and labels datasets for the training\n",
    "                labels = np.array(sequences_df[\"class\"])\n",
    "                # print(\"label extracted\")\n",
    "                features = sequences_df.drop(\"nameseq\", axis = 1).drop(\"class\", axis = 1).values\n",
    "                # print(\"features extracted\")\n",
    "                # features = features.astype(np.float)\n",
    "                # print(\"features type casted\")\n",
    "                features = features.reshape(features.shape + (1,))\n",
    "                \n",
    "                # input_size = (features.shape[1], features.shape[2])\n",
    "                \n",
    "                ## Parameters to Read/Write the k-fold dataset to file\n",
    "                foldPath = os.path.join(result_output_path, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "                foldName = file.split(\".\")[0]+\"_{}fold\".format(n_fold)+\".pickle\"\n",
    "\n",
    "                ##### ADDITIONAL CHANGES - USE PREVIOUS GENERATED FOLDS IF AVAILABLE\n",
    "\n",
    "                if(os.path.isfile(os.path.join(foldPath, foldName))):\n",
    "                    folds = pickle.load(open(os.path.join(foldPath, foldName), \"rb\"))\n",
    "                else:\n",
    "                    ## Generate the k-fold dataset\n",
    "                    folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "                    if(not os.path.isdir(foldPath)):\n",
    "                        os.makedirs(foldPath)\n",
    "                    pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "                    \n",
    "                print(\"MODEL!\")    \n",
    "                \n",
    "                for modelName in modelNames:\n",
    "\n",
    "                    ## Create and set directory to save model\n",
    "                    modelPath = os.path.join(result_output_path, current_dataset_variety, \"{}fold\".format(n_fold), \"models\", modelName)\n",
    "                    if(not os.path.isdir(modelPath)):\n",
    "                        os.makedirs(modelPath)\n",
    "\n",
    "                    ## fold counter\n",
    "                    i = 0\n",
    "\n",
    "                    for fold in folds:\n",
    "\n",
    "                        print(\"\\nTrain/Test model \"+modelName+\" on Fold #\"+str(i)+\".\")\n",
    "\n",
    "                        ## Generate model using function\n",
    "                        model = RandomForestClassifier(n_estimators=100, \n",
    "                                                       criterion='gini', \n",
    "                                                       bootstrap=True,\n",
    "                                                       oob_score=True, \n",
    "                                                       warm_start = True)\n",
    "                        \n",
    "                        # model = ExtraTreesClassifier(n_estimators=50, \n",
    "                        #                              criterion='gini', \n",
    "                        #                              bootstrap=True,\n",
    "                        #                              oob_score=True, \n",
    "                        #                              warm_start = True)\n",
    "                        \n",
    "                        # model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "                        \n",
    "                        # model = SVC(C = 2,\n",
    "                        #             kernel = \"rbf\",\n",
    "                        #             # degree = 5, # only for kernel = poly\n",
    "                        #             gamma = \"scale\", # only for kernel = rbf/poly/sigmoid\n",
    "                        #             max_iter = -1)\n",
    "                        \n",
    "                        model.fit(X = fold[\"X_train\"].reshape(fold[\"X_train\"].shape[0], fold[\"X_train\"].shape[1]), \n",
    "                                  y = fold[\"y_train\"])\n",
    "                        \n",
    "                        # model_filename = \"{}_fold{}_model.pickle\".format(encoding_type, i)\n",
    "                        \n",
    "                        # model_file_obj = open(os.path.join(modelPath, model_filename), 'wb')\n",
    "                        # pickle.dump(model, model_file_obj)\n",
    "                        # model_file_obj.close()\n",
    "                        \n",
    "                        ## Generate model using function\n",
    "                        # model = Conv_LSTM_DLNN(input_shape = input_size, \n",
    "                        #                        conv_filters_per_layer = 50, kernel_length = kernel_length, \n",
    "                        #                        lstm_decode_units = 50,\n",
    "                        #                        prob = 0.5, \n",
    "                        #                        learn_rate = 0.001, loss = 'binary_crossentropy', metrics = None, \n",
    "                        #                        max_pool_width = 2, max_pool_stride = 2, \n",
    "                        #                        dense_decode_units = 150)\n",
    "                        \n",
    "                        # input_size = (fold[\"X_train\"].shape[1],)\n",
    "                        \n",
    "                        ## Generate model using function\n",
    "                        # model = FCNN(input_shape=input_size, \n",
    "                        #              dense_decode_units_1 = input_size[0],\n",
    "                        #              dense_decode_units_2 = 150,\n",
    "                        #              max_pool_stride = 2, max_pool_width = 2,\n",
    "                        #              learn_rate = 0.001, prob = 0.5, loss = 'binary_crossentropy', metrics = None)\n",
    "                        \n",
    "                        ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "                        # modelCallbacks = [\n",
    "                        #     tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(modelName, i)),\n",
    "                        #                                        monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "                        #                                        save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "                        #     tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, \n",
    "                        #                                      mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "                        # ]\n",
    "                        # model.fit(x = fold[\"X_train\"].reshape(fold[\"X_train\"].shape[0], fold[\"X_train\"].shape[1]), \n",
    "                        #           y = fold[\"y_train\"], batch_size = batch_size, epochs = epochs, verbose = 0, \n",
    "                        #           callbacks = modelCallbacks, validation_data = (fold[\"X_test\"].reshape(fold[\"X_test\"].shape[0], fold[\"X_test\"].shape[1]), \n",
    "                        #                                                          fold[\"y_test\"]))\n",
    "\n",
    "                        ##################################################################################\n",
    "                        ##### Prediction and metrics for TRAIN dataset\n",
    "                        ##################################################################################\n",
    "\n",
    "                        y_pred = model.predict(fold[\"X_train\"].reshape(fold[\"X_train\"].shape[0], fold[\"X_train\"].shape[1]))\n",
    "                        label_pred = pred2label(y_pred)\n",
    "                        # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                        acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "                        prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "                        conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "                        if(conf[0][0]+conf[1][0]):\n",
    "                            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                        else:\n",
    "                            sens = 0.0\n",
    "                        if(conf[1][1]+conf[0][1]):\n",
    "                            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                        else:\n",
    "                            spec = 0.0\n",
    "                        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                        else:\n",
    "                            mcc= 0.0\n",
    "                        fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "                        auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "                        evaluations[\"Model\"].append(modelName)\n",
    "                        evaluations[\"Encoding_Type\"].append(encoding_type)\n",
    "                        evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                        evaluations[\"Fold\"].append(i)\n",
    "                        evaluations[\"Train_Test\"].append(\"Train\")\n",
    "                        evaluations[\"Accuracy\"].append(acc)\n",
    "                        evaluations[\"Precision\"].append(prec)\n",
    "                        evaluations[\"TPR\"].append(tpr)\n",
    "                        evaluations[\"FPR\"].append(fpr)\n",
    "                        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                        evaluations[\"AUC\"].append(auc)\n",
    "                        evaluations[\"Sensitivity\"].append(sens)\n",
    "                        evaluations[\"Specificity\"].append(spec)\n",
    "                        evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "                        ##################################################################################\n",
    "                        ##### Prediction and metrics for TEST dataset\n",
    "                        ##################################################################################\n",
    "\n",
    "                        y_pred = model.predict(fold[\"X_test\"].reshape(fold[\"X_test\"].shape[0], fold[\"X_test\"].shape[1]))\n",
    "                        label_pred = pred2label(y_pred)\n",
    "                        # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                        acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "                        prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "                        conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "                        if(conf[0][0]+conf[1][0]):\n",
    "                            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                        else:\n",
    "                            sens = 0.0\n",
    "                        if(conf[1][1]+conf[0][1]):\n",
    "                            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                        else:\n",
    "                            spec = 0.0\n",
    "                        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                        else:\n",
    "                            mcc= 0.0\n",
    "                        fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "                        auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "                        evaluations[\"Model\"].append(modelName)\n",
    "                        evaluations[\"Encoding_Type\"].append(encoding_type)\n",
    "                        evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                        evaluations[\"Fold\"].append(i)\n",
    "                        evaluations[\"Train_Test\"].append(\"Test\")\n",
    "                        evaluations[\"Accuracy\"].append(acc)\n",
    "                        evaluations[\"Precision\"].append(prec)\n",
    "                        evaluations[\"TPR\"].append(tpr)\n",
    "                        evaluations[\"FPR\"].append(fpr)\n",
    "                        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                        evaluations[\"AUC\"].append(auc)\n",
    "                        evaluations[\"Sensitivity\"].append(sens)\n",
    "                        evaluations[\"Specificity\"].append(spec)\n",
    "                        evaluations[\"MCC\"].append(mcc)\n",
    "                        \n",
    "                        i = i+1\n",
    "                        \n",
    "            except Exception as error:\n",
    "                error_list.append((input_file_full_path, error))\n",
    "                \n",
    "##################################################################################\n",
    "##### Dump evaluations to a file\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(result_output_path, \"_Evaluation_All_Datasets\", \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "pickle.dump(evaluations,\n",
    "            open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelNames[0])), \"wb\"))\n",
    "\n",
    "##################################################################################\n",
    "##### Dump exceptions to a file\n",
    "##################################################################################\n",
    "\n",
    "pickle.dump(error_list,\n",
    "            open(os.path.join(result_output_path, \"exceptions.pickle\"), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Parameters used only in this section\n",
    "# ##################################################################################\n",
    "\n",
    "# n_fold = 10\n",
    "\n",
    "# expName = \"MathFeature_setting1_kgap_fickett\"\n",
    "# outPath = \"Generated\"\n",
    "# setting = \"Setting1\"\n",
    "# output_path = \"Results\"\n",
    "\n",
    "# modelNames = [\"RandomForest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, output_path, setting, \"_Evaluation_All_Datasets\", \"{}fold\".format(n_fold))\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelNames[0])), \"rb\"))\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Encoding_Type</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.797391</td>\n",
       "      <td>0.831740</td>\n",
       "      <td>[0.0, 0.75, 1.0]</td>\n",
       "      <td>[0.0, 0.1543859649122807, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.797807</td>\n",
       "      <td>0.768740</td>\n",
       "      <td>0.831740</td>\n",
       "      <td>0.598042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.816522</td>\n",
       "      <td>0.834846</td>\n",
       "      <td>[0.0, 0.7931034482758621, 1.0]</td>\n",
       "      <td>[0.0, 0.15964912280701754, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.816727</td>\n",
       "      <td>0.799666</td>\n",
       "      <td>0.834846</td>\n",
       "      <td>0.633983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.833043</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>[0.0, 0.8137931034482758, 1.0]</td>\n",
       "      <td>[0.0, 0.14736842105263157, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.833212</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.666764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.844348</td>\n",
       "      <td>0.856128</td>\n",
       "      <td>[0.0, 0.8310344827586207, 1.0]</td>\n",
       "      <td>[0.0, 0.14210526315789473, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.844465</td>\n",
       "      <td>0.833049</td>\n",
       "      <td>0.856128</td>\n",
       "      <td>0.689053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.827826</td>\n",
       "      <td>0.835088</td>\n",
       "      <td>[0.0, 0.8206896551724138, 1.0]</td>\n",
       "      <td>[0.0, 0.1649122807017544, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>0.835088</td>\n",
       "      <td>0.655777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.999513</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0004791566842357451, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999513</td>\n",
       "      <td>0.999517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.803865</td>\n",
       "      <td>0.841758</td>\n",
       "      <td>[0.0, 0.745136186770428, 1.0]</td>\n",
       "      <td>[0.0, 0.1381957773512476, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.803470</td>\n",
       "      <td>0.774138</td>\n",
       "      <td>0.841758</td>\n",
       "      <td>0.611402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.915942</td>\n",
       "      <td>0.893186</td>\n",
       "      <td>[0.0, 0.943579766536965, 1.0]</td>\n",
       "      <td>[0.0, 0.11132437619961612, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.916128</td>\n",
       "      <td>0.941057</td>\n",
       "      <td>0.893186</td>\n",
       "      <td>0.833249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.889855</td>\n",
       "      <td>0.845754</td>\n",
       "      <td>[0.0, 0.9512670565302144, 1.0]</td>\n",
       "      <td>[0.0, 0.17049808429118773, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.890384</td>\n",
       "      <td>0.945415</td>\n",
       "      <td>0.845754</td>\n",
       "      <td>0.785952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.864469</td>\n",
       "      <td>[0.0, 0.9200779727095516, 1.0]</td>\n",
       "      <td>[0.0, 0.1417624521072797, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.889158</td>\n",
       "      <td>0.916155</td>\n",
       "      <td>0.864469</td>\n",
       "      <td>0.779469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.885024</td>\n",
       "      <td>0.868914</td>\n",
       "      <td>[0.0, 0.9044834307992202, 1.0]</td>\n",
       "      <td>[0.0, 0.13409961685823754, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.885192</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.868914</td>\n",
       "      <td>0.770747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.780886</td>\n",
       "      <td>[0.0, 0.7362637362637363, 1.0]</td>\n",
       "      <td>[0.0, 0.20434782608695654, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.765958</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.780886</td>\n",
       "      <td>0.532943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.853552</td>\n",
       "      <td>0.815324</td>\n",
       "      <td>[0.0, 0.9120879120879121, 1.0]</td>\n",
       "      <td>[0.0, 0.20434782608695654, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.853870</td>\n",
       "      <td>0.901478</td>\n",
       "      <td>0.815324</td>\n",
       "      <td>0.712257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.841530</td>\n",
       "      <td>0.789179</td>\n",
       "      <td>[0.0, 0.9296703296703297, 1.0]</td>\n",
       "      <td>[0.0, 0.24565217391304348, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.842009</td>\n",
       "      <td>0.915567</td>\n",
       "      <td>0.789179</td>\n",
       "      <td>0.694305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.856674</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>[0.0, 0.920704845814978, 1.0]</td>\n",
       "      <td>[0.0, 0.20652173913043478, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.857092</td>\n",
       "      <td>0.910224</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.719591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.841357</td>\n",
       "      <td>0.807157</td>\n",
       "      <td>[0.0, 0.8942731277533039, 1.0]</td>\n",
       "      <td>[0.0, 0.2108695652173913, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.841702</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.807157</td>\n",
       "      <td>0.686877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.991713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.9840425531914894, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.992021</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.994695</td>\n",
       "      <td>[0.0, 0.9973404255319149, 1.0]</td>\n",
       "      <td>[0.0, 0.005747126436781609, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.994695</td>\n",
       "      <td>0.991703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.998619</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0028735632183908046, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.997237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.979282</td>\n",
       "      <td>0.971279</td>\n",
       "      <td>[0.0, 0.9893617021276596, 1.0]</td>\n",
       "      <td>[0.0, 0.031609195402298854, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.978876</td>\n",
       "      <td>0.988270</td>\n",
       "      <td>0.971279</td>\n",
       "      <td>0.958650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ALL-v2</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.997238</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.005747126436781609, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.997126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.994481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Encoding_Type       Dataset  Fold Train_Test  Accuracy  \\\n",
       "0   RandomForest        ALL-v2    Drosophila     0      Train  1.000000   \n",
       "1   RandomForest        ALL-v2    Drosophila     0       Test  0.797391   \n",
       "2   RandomForest        ALL-v2    Drosophila     1      Train  1.000000   \n",
       "3   RandomForest        ALL-v2    Drosophila     1       Test  0.816522   \n",
       "4   RandomForest        ALL-v2    Drosophila     2      Train  1.000000   \n",
       "5   RandomForest        ALL-v2    Drosophila     2       Test  0.833043   \n",
       "6   RandomForest        ALL-v2    Drosophila     3      Train  1.000000   \n",
       "7   RandomForest        ALL-v2    Drosophila     3       Test  0.844348   \n",
       "8   RandomForest        ALL-v2    Drosophila     4      Train  1.000000   \n",
       "9   RandomForest        ALL-v2    Drosophila     4       Test  0.827826   \n",
       "10  RandomForest        ALL-v2       Elegans     0      Train  0.999758   \n",
       "11  RandomForest        ALL-v2       Elegans     0       Test  0.803865   \n",
       "12  RandomForest        ALL-v2       Elegans     1      Train  1.000000   \n",
       "13  RandomForest        ALL-v2       Elegans     1       Test  0.915942   \n",
       "14  RandomForest        ALL-v2       Elegans     2      Train  1.000000   \n",
       "15  RandomForest        ALL-v2       Elegans     2       Test  0.889855   \n",
       "16  RandomForest        ALL-v2       Elegans     3      Train  1.000000   \n",
       "17  RandomForest        ALL-v2       Elegans     3       Test  0.888889   \n",
       "18  RandomForest        ALL-v2       Elegans     4      Train  1.000000   \n",
       "19  RandomForest        ALL-v2       Elegans     4       Test  0.885024   \n",
       "20  RandomForest        ALL-v2  Homo_Sapiens     0      Train  1.000000   \n",
       "21  RandomForest        ALL-v2  Homo_Sapiens     0       Test  0.766120   \n",
       "22  RandomForest        ALL-v2  Homo_Sapiens     1      Train  1.000000   \n",
       "23  RandomForest        ALL-v2  Homo_Sapiens     1       Test  0.853552   \n",
       "24  RandomForest        ALL-v2  Homo_Sapiens     2      Train  1.000000   \n",
       "25  RandomForest        ALL-v2  Homo_Sapiens     2       Test  0.841530   \n",
       "26  RandomForest        ALL-v2  Homo_Sapiens     3      Train  1.000000   \n",
       "27  RandomForest        ALL-v2  Homo_Sapiens     3       Test  0.856674   \n",
       "28  RandomForest        ALL-v2  Homo_Sapiens     4      Train  1.000000   \n",
       "29  RandomForest        ALL-v2  Homo_Sapiens     4       Test  0.841357   \n",
       "30  RandomForest        ALL-v2         Yeast     0      Train  1.000000   \n",
       "31  RandomForest        ALL-v2         Yeast     0       Test  0.991713   \n",
       "32  RandomForest        ALL-v2         Yeast     1      Train  1.000000   \n",
       "33  RandomForest        ALL-v2         Yeast     1       Test  0.995856   \n",
       "34  RandomForest        ALL-v2         Yeast     2      Train  1.000000   \n",
       "35  RandomForest        ALL-v2         Yeast     2       Test  0.998619   \n",
       "36  RandomForest        ALL-v2         Yeast     3      Train  1.000000   \n",
       "37  RandomForest        ALL-v2         Yeast     3       Test  0.979282   \n",
       "38  RandomForest        ALL-v2         Yeast     4      Train  1.000000   \n",
       "39  RandomForest        ALL-v2         Yeast     4       Test  0.997238   \n",
       "\n",
       "    Precision                             TPR  \\\n",
       "0    1.000000                 [0.0, 1.0, 1.0]   \n",
       "1    0.831740                [0.0, 0.75, 1.0]   \n",
       "2    1.000000                 [0.0, 1.0, 1.0]   \n",
       "3    0.834846  [0.0, 0.7931034482758621, 1.0]   \n",
       "4    1.000000                 [0.0, 1.0, 1.0]   \n",
       "5    0.848921  [0.0, 0.8137931034482758, 1.0]   \n",
       "6    1.000000                 [0.0, 1.0, 1.0]   \n",
       "7    0.856128  [0.0, 0.8310344827586207, 1.0]   \n",
       "8    1.000000                 [0.0, 1.0, 1.0]   \n",
       "9    0.835088  [0.0, 0.8206896551724138, 1.0]   \n",
       "10   0.999513                 [0.0, 1.0, 1.0]   \n",
       "11   0.841758   [0.0, 0.745136186770428, 1.0]   \n",
       "12   1.000000                 [0.0, 1.0, 1.0]   \n",
       "13   0.893186   [0.0, 0.943579766536965, 1.0]   \n",
       "14   1.000000                 [0.0, 1.0, 1.0]   \n",
       "15   0.845754  [0.0, 0.9512670565302144, 1.0]   \n",
       "16   1.000000                 [0.0, 1.0, 1.0]   \n",
       "17   0.864469  [0.0, 0.9200779727095516, 1.0]   \n",
       "18   1.000000                 [0.0, 1.0, 1.0]   \n",
       "19   0.868914  [0.0, 0.9044834307992202, 1.0]   \n",
       "20   1.000000                 [0.0, 1.0, 1.0]   \n",
       "21   0.780886  [0.0, 0.7362637362637363, 1.0]   \n",
       "22   1.000000                 [0.0, 1.0, 1.0]   \n",
       "23   0.815324  [0.0, 0.9120879120879121, 1.0]   \n",
       "24   1.000000                 [0.0, 1.0, 1.0]   \n",
       "25   0.789179  [0.0, 0.9296703296703297, 1.0]   \n",
       "26   1.000000                 [0.0, 1.0, 1.0]   \n",
       "27   0.814815   [0.0, 0.920704845814978, 1.0]   \n",
       "28   1.000000                 [0.0, 1.0, 1.0]   \n",
       "29   0.807157  [0.0, 0.8942731277533039, 1.0]   \n",
       "30   1.000000                 [0.0, 1.0, 1.0]   \n",
       "31   1.000000  [0.0, 0.9840425531914894, 1.0]   \n",
       "32   1.000000                 [0.0, 1.0, 1.0]   \n",
       "33   0.994695  [0.0, 0.9973404255319149, 1.0]   \n",
       "34   1.000000                 [0.0, 1.0, 1.0]   \n",
       "35   0.997347                 [0.0, 1.0, 1.0]   \n",
       "36   1.000000                 [0.0, 1.0, 1.0]   \n",
       "37   0.971279  [0.0, 0.9893617021276596, 1.0]   \n",
       "38   1.000000                 [0.0, 1.0, 1.0]   \n",
       "39   0.994709                 [0.0, 1.0, 1.0]   \n",
       "\n",
       "                                  FPR TPR_FPR_Thresholds       AUC  \\\n",
       "0                     [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "1      [0.0, 0.1543859649122807, 1.0]          [2, 1, 0]  0.797807   \n",
       "2                     [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "3     [0.0, 0.15964912280701754, 1.0]          [2, 1, 0]  0.816727   \n",
       "4                     [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "5     [0.0, 0.14736842105263157, 1.0]          [2, 1, 0]  0.833212   \n",
       "6                     [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "7     [0.0, 0.14210526315789473, 1.0]          [2, 1, 0]  0.844465   \n",
       "8                     [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "9      [0.0, 0.1649122807017544, 1.0]          [2, 1, 0]  0.827889   \n",
       "10  [0.0, 0.0004791566842357451, 1.0]          [2, 1, 0]  0.999760   \n",
       "11     [0.0, 0.1381957773512476, 1.0]          [2, 1, 0]  0.803470   \n",
       "12                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "13    [0.0, 0.11132437619961612, 1.0]          [2, 1, 0]  0.916128   \n",
       "14                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "15    [0.0, 0.17049808429118773, 1.0]          [2, 1, 0]  0.890384   \n",
       "16                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "17     [0.0, 0.1417624521072797, 1.0]          [2, 1, 0]  0.889158   \n",
       "18                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "19    [0.0, 0.13409961685823754, 1.0]          [2, 1, 0]  0.885192   \n",
       "20                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "21    [0.0, 0.20434782608695654, 1.0]          [2, 1, 0]  0.765958   \n",
       "22                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "23    [0.0, 0.20434782608695654, 1.0]          [2, 1, 0]  0.853870   \n",
       "24                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "25    [0.0, 0.24565217391304348, 1.0]          [2, 1, 0]  0.842009   \n",
       "26                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "27    [0.0, 0.20652173913043478, 1.0]          [2, 1, 0]  0.857092   \n",
       "28                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "29     [0.0, 0.2108695652173913, 1.0]          [2, 1, 0]  0.841702   \n",
       "30                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "31                    [0.0, 0.0, 1.0]          [2, 1, 0]  0.992021   \n",
       "32                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "33   [0.0, 0.005747126436781609, 1.0]          [2, 1, 0]  0.995797   \n",
       "34                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "35  [0.0, 0.0028735632183908046, 1.0]          [2, 1, 0]  0.998563   \n",
       "36                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "37   [0.0, 0.031609195402298854, 1.0]          [2, 1, 0]  0.978876   \n",
       "38                    [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "39   [0.0, 0.005747126436781609, 1.0]          [2, 1, 0]  0.997126   \n",
       "\n",
       "    Sensitivity  Specificity       MCC  \n",
       "0      1.000000     1.000000  1.000000  \n",
       "1      0.768740     0.831740  0.598042  \n",
       "2      1.000000     1.000000  1.000000  \n",
       "3      0.799666     0.834846  0.633983  \n",
       "4      1.000000     1.000000  1.000000  \n",
       "5      0.818182     0.848921  0.666764  \n",
       "6      1.000000     1.000000  1.000000  \n",
       "7      0.833049     0.856128  0.689053  \n",
       "8      1.000000     1.000000  1.000000  \n",
       "9      0.820690     0.835088  0.655777  \n",
       "10     1.000000     0.999513  0.999517  \n",
       "11     0.774138     0.841758  0.611402  \n",
       "12     1.000000     1.000000  1.000000  \n",
       "13     0.941057     0.893186  0.833249  \n",
       "14     1.000000     1.000000  1.000000  \n",
       "15     0.945415     0.845754  0.785952  \n",
       "16     1.000000     1.000000  1.000000  \n",
       "17     0.916155     0.864469  0.779469  \n",
       "18     1.000000     1.000000  1.000000  \n",
       "19     0.902196     0.868914  0.770747  \n",
       "20     1.000000     1.000000  1.000000  \n",
       "21     0.753086     0.780886  0.532943  \n",
       "22     1.000000     1.000000  1.000000  \n",
       "23     0.901478     0.815324  0.712257  \n",
       "24     1.000000     1.000000  1.000000  \n",
       "25     0.915567     0.789179  0.694305  \n",
       "26     1.000000     1.000000  1.000000  \n",
       "27     0.910224     0.814815  0.719591  \n",
       "28     1.000000     1.000000  1.000000  \n",
       "29     0.883212     0.807157  0.686877  \n",
       "30     1.000000     1.000000  1.000000  \n",
       "31     0.983051     1.000000  0.983547  \n",
       "32     1.000000     1.000000  1.000000  \n",
       "33     0.997118     0.994695  0.991703  \n",
       "34     1.000000     1.000000  1.000000  \n",
       "35     1.000000     0.997347  0.997237  \n",
       "36     1.000000     1.000000  1.000000  \n",
       "37     0.988270     0.971279  0.958650  \n",
       "38     1.000000     1.000000  1.000000  \n",
       "39     1.000000     0.994709  0.994481  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Dataset\",\n",
    "                                                 \"Encoding_Type\",\n",
    "                                                 \"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "# Eval_Train = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(3), ['Train'])]\n",
    "# Eval_Test = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(3), ['Test'])]\n",
    "\n",
    "# datasets = np.unique(evaluations_df_grouped.index.get_level_values(0))\n",
    "\n",
    "# evaluations_df_grouped = evaluations_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Available :  ['Accuracy', 'Precision', 'AUC', 'Sensitivity', 'Specificity', 'MCC']\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Decide on metric to visualize\n",
    "##################################################################################\n",
    "\n",
    "print(\"Metrics Available : \", list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Visualize with a multiple Bar chart\n",
    "##################################################################################\n",
    "\n",
    "# df = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), [dataset_to_print])]\n",
    "# df = evaluations_df_grouped.reset_index(level=['Dataset', 'Encoding_Type', 'Train_Test'])\n",
    "df = evaluations_df_grouped.reset_index()\n",
    "\n",
    "# Some boilerplate to initialise things\n",
    "sns.set()\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "# Draw the bars\n",
    "ax = sns.barplot(data=df, x=\"Dataset\", y=metric_to_plot, hue=\"Train_Test\")\n",
    "\n",
    "# Customise some display properties\n",
    "ax.set_title(metric_to_plot)\n",
    "ax.grid(color='#cccccc')\n",
    "ax.set_ylabel(metric_to_plot)\n",
    "ax.set_xlabel(\"Dataset\")\n",
    "ax.set_xticklabels(df[\"Dataset\"].unique().astype(str), rotation='vertical')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height()*100, '.4f'),\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                size=15,\n",
    "                xytext = (0, -12), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "##############################\n",
    "\n",
    "# Ask Matplotlib to show it\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Iteratively generate comparison plot using every metric\n",
    "##################################################################################\n",
    "\n",
    "for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "    # df = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), [dataset_to_print])]\n",
    "    # df = evaluations_df_grouped.reset_index(level=['Dataset', 'Encoding_Type', 'Train_Test'])\n",
    "    df = evaluations_df_grouped.reset_index()\n",
    "\n",
    "    # Some boilerplate to initialise things\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(20,8))\n",
    "\n",
    "    # Draw the bars\n",
    "    ax = sns.barplot(data=df, x=\"Dataset\", y=metric_to_plot, hue=\"Train_Test\")\n",
    "\n",
    "    # Customise some display properties\n",
    "    ax.set_title(metric_to_plot)\n",
    "    ax.grid(color='#cccccc')\n",
    "    ax.set_ylabel(metric_to_plot)\n",
    "    ax.set_xlabel(\"Dataset\")\n",
    "    ax.set_xticklabels(df[\"Dataset\"].unique().astype(str), rotation='vertical')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height()*100, '.4f'),\n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    size=15,\n",
    "                    xytext = (0, -12), \n",
    "                    textcoords = 'offset points')\n",
    "        \n",
    "    plt.savefig(os.path.join(evalPath, \"{}_{}_Comparison\".format(metric_to_plot, modelNames[0])))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
