{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# import xgboost as xgb\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all experiment parameters\n",
    "##################################################################################\n",
    "\n",
    "expName = \"MathFeature_setting1\"\n",
    "outPath = \"Generated\"\n",
    "\n",
    "dataset_path = \"Datasets\"\n",
    "setting = \"Setting1\"\n",
    "output_path = \"Results_ALL\"\n",
    "\n",
    "datafile_extensions = \".csv\"\n",
    "\n",
    "modelNames = [\"FCNN\"]\n",
    "\n",
    "shuffle = False\n",
    "seed = None\n",
    "\n",
    "reject_encoding_list = [\"NM-complex\", \"kmer\", \"kstep\", \"rckmer\", \"ALL\"]\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "kernel_length = 5\n",
    "\n",
    "##################################################################################\n",
    "##### Define the modelling hyperparameters\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Checking the directory\n",
    "##################################################################################\n",
    "\n",
    "dataset_setting_path = os.path.join(outPath, expName, dataset_path, setting)\n",
    "dataset_varieties = next(os.walk(dataset_setting_path))\n",
    "result_output_path = os.path.join(outPath, expName, output_path, setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN network architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def Conv_LSTM_DLNN(input_shape=(150,4), \n",
    "                   conv_filters_per_layer = 50, kernel_length = 5, \n",
    "                   lstm_decode_units = 50,\n",
    "                   learn_rate = 0.0003, prob = 0.5, loss = 'binary_crossentropy', metrics = None, max_pool_width = 2, \n",
    "                   max_pool_stride = 2, \n",
    "                   dense_decode_units = 150):\n",
    "        \n",
    "    beta = 0.001\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(conv_filters_per_layer, kernel_length, input_shape = input_shape, kernel_regularizer=tf.keras.regularizers.l2(beta), padding=\"same\"))\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool1D(pool_size = max_pool_width, strides = max_pool_stride))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, kernel_regularizer = tf.keras.regularizers.l2(beta), dropout = 0.1))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras .layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(dense_decode_units, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='sigmoid'))\n",
    "    \n",
    "    #[tf.keras.metrics.binary_accuracy, metrics.precision, metrics.recall, metrics.f1score])\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss, metrics = metrics) \n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "##################################################################################\n",
    "##### Function to customize the DLNN network architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def FCNN(input_shape=(150,4), \n",
    "         dense_decode_units_1 = 150,\n",
    "         dense_decode_units_2 = 150,\n",
    "         max_pool_stride = 2, max_pool_width = 2,\n",
    "         learn_rate = 0.0003, prob = 0.5, loss = 'binary_crossentropy', metrics = None):\n",
    "        \n",
    "    beta = 0.001\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # model.add(tf.keras.layers.Dense(dense_decode_units_1, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dense(dense_decode_units_1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(dense_decode_units_1))\n",
    "\n",
    "    # model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    # model.add(tf.keras.layers.Dense(dense_decode_units_2, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dense(dense_decode_units_2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(dense_decode_units_2))\n",
    "\n",
    "    # model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    # model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #[tf.keras.metrics.binary_accuracy, metrics.precision, metrics.recall, metrics.f1score])\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss, metrics = metrics) \n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation by joining from all encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_variety in dataset_varieties[1]:\n",
    "#     current_dataset_variety_path = os.path.join(dataset_setting_path, dataset_variety)\n",
    "    \n",
    "    \n",
    "#     print(\"\\nProcessing variety: \", dataset_variety)\n",
    "#     print(\"======================================\")\n",
    "    \n",
    "#     i = 0\n",
    "    \n",
    "#     for root, dirs, files in os.walk(current_dataset_variety_path):\n",
    "#         for file in files:\n",
    "#             if os.path.splitext(file)[-1] == datafile_extensions:\n",
    "                \n",
    "#                 encoding_type = file.split(\".\")[0].split(\"_\")[-1]\n",
    "                \n",
    "#                 if encoding_type not in reject_encoding_list:\n",
    "                \n",
    "#                     input_file_full_path = os.path.join(root, file)\n",
    "\n",
    "#                     ## check if input file has header\n",
    "#                     file_obj = open(input_file_full_path, \"r\")\n",
    "#                     first_line = file_obj.readline()\n",
    "#                     file_obj.close()\n",
    "#                     file_has_header = None\n",
    "#                     if first_line.split(\",\")[0] == \"nameseq\" or first_line.replace(\"\\n\", \"\").split(\",\")[-1] == \"label\":\n",
    "#                         file_has_header = 0\n",
    "\n",
    "#                     sequences_df = pd.read_csv(input_file_full_path, header = file_has_header)\n",
    "                    \n",
    "#                     ## adding encoding type to header names\n",
    "#                     cols = list(sequences_df.columns)\n",
    "#                     cols = [encoding_type+\"_\"+str(col) for col in cols]\n",
    "#                     sequences_df.columns = cols\n",
    "                    \n",
    "#                     # sequences_df = pd.read_csv(input_file_full_path, header = \"infer\")\n",
    "#                     # print(\"Encoding completed adding: \", encoding_type)\n",
    "#                     # print(\"Columns: \", sequences_df.columns)\n",
    "                    \n",
    "#                     sequences_df = sequences_df.rename(columns = {sequences_df.columns[0] : 'nameseq', \n",
    "#                                                                   sequences_df.columns[-1] : 'label'})\n",
    "                    \n",
    "#                     sequences_df = sequences_df.drop(\"label\", axis = 1)\n",
    "                    \n",
    "#                     if i == 0:\n",
    "#                         variety_dataset_df = sequences_df\n",
    "                        \n",
    "#                     else:\n",
    "#                         # variety_dataset_df = pd.concat([variety_dataset_df, sequences_df], \n",
    "#                         #                                join=\"inner\", \n",
    "#                         #                                keys = (\"nameseq\"), \n",
    "#                         #                                ignore_index = True, \n",
    "#                         #                                axis = 1)\n",
    "#                         # variety_dataset_df = variety_dataset_df.rename(columns = {0 : 'nameseq'})\n",
    "                        \n",
    "#                         variety_dataset_df = pd.merge(variety_dataset_df, sequences_df, \n",
    "#                                                       left_on='nameseq', right_on='nameseq', \n",
    "#                                                       how='inner')\n",
    "                    \n",
    "#                     print(\"Encoding completed adding: \", encoding_type)\n",
    "                    \n",
    "#                     i = i+1\n",
    "                    \n",
    "#     file_name = \"_\".join(file.split(\".\")[0].split(\"_\")[0:-1]+[\"ALL\"])+\".\"+file.split(\".\")[1]\n",
    "#     variety_dataset_df.to_csv(os.path.join(root, file_name), \n",
    "#                               header = True, \n",
    "#                               index = False)\n",
    "    \n",
    "#     print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan/Infinity correction - dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root, dirs, files in os.walk(dataset_setting_path):\n",
    "#     for file in files:\n",
    "#         if (os.path.splitext(file)[-1] == datafile_extensions) & (file.split(\".\")[0].split(\"_\")[-1] == \"ALL\"):\n",
    "            \n",
    "#             input_file_full_path = os.path.join(root, file)\n",
    "            \n",
    "#             print(\" Processing file : \",input_file_full_path)\n",
    "            \n",
    "#             sequences_df = pd.read_csv(input_file_full_path, header = \"infer\", low_memory=False)\n",
    "            \n",
    "#             vals = sequences_df.drop(\"nameseq\", axis = 1).values.astype(np.float)\n",
    "#             sequences_df_columns = sequences_df.drop(\"nameseq\", axis = 1).columns\n",
    "\n",
    "#             if np.isnan(np.max(vals)):\n",
    "#                 nans = np.argwhere(np.isnan(vals.astype(np.float)))\n",
    "#                 vals = np.delete(vals, np.unique(nans[:,1]), axis=1)\n",
    "#                 drop_cols = sequences_df_columns[np.unique(nans[:,1])]\n",
    "#                 for drop_col in drop_cols:\n",
    "#                     sequences_df = sequences_df.drop(drop_col, axis = 1)\n",
    "\n",
    "#             sequences_df_columns = sequences_df.drop(\"nameseq\", axis = 1).columns\n",
    "\n",
    "#             if np.max(vals)>1e+308:\n",
    "#                 vals = np.where(vals == np.max(vals), \n",
    "#                                 None, \n",
    "#                                 vals)\n",
    "#                 nans = np.argwhere(np.isnan(vals.astype(np.float)))\n",
    "#                 vals = np.delete(vals, np.unique(nans[:,1]), axis=1)\n",
    "#                 drop_cols = sequences_df_columns[np.unique(nans[:,1])]\n",
    "#                 for drop_col in drop_cols:\n",
    "#                     sequences_df = sequences_df.drop(drop_col, axis = 1)\n",
    "                    \n",
    "#             sequences_df.to_csv(input_file_full_path.replace(\"_ALL\", \"_ALL-v2\"), \n",
    "#                                 header = True, \n",
    "#                                 index = False)\n",
    "            \n",
    "#             print(\" Generated file : \",input_file_full_path.replace(\"_ALL\", \"_ALL-v2\"))\n",
    "#             print(\"\\n################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "File: Generated\\MathFeature_setting1\\Datasets\\Setting1\\Drosophila\\nucleosomes_vs_linkers_melanogaster_ALL-v2.csv\n",
      "Nucleosomi: 2900\n",
      "Linker: 2850\n",
      "MODEL!\n",
      "\n",
      "Train/Test model FCNN on Fold #0.\n",
      "\n",
      "Train/Test model FCNN on Fold #1.\n",
      "\n",
      "Train/Test model FCNN on Fold #2.\n",
      "\n",
      "Train/Test model FCNN on Fold #3.\n",
      "\n",
      "Train/Test model FCNN on Fold #4.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "File: Generated\\MathFeature_setting1\\Datasets\\Setting1\\Elegans\\nucleosomes_vs_linkers_elegans_ALL-v2.csv\n",
      "Nucleosomi: 2567\n",
      "Linker: 2608\n",
      "MODEL!\n",
      "\n",
      "Train/Test model FCNN on Fold #0.\n",
      "\n",
      "Train/Test model FCNN on Fold #1.\n",
      "\n",
      "Train/Test model FCNN on Fold #2.\n",
      "\n",
      "Train/Test model FCNN on Fold #3.\n",
      "\n",
      "Train/Test model FCNN on Fold #4.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "File: Generated\\MathFeature_setting1\\Datasets\\Setting1\\Homo_Sapiens\\nucleosomes_vs_linkers_sapiens_ALL-v2.csv\n",
      "Nucleosomi: 2273\n",
      "Linker: 2300\n",
      "MODEL!\n",
      "\n",
      "Train/Test model FCNN on Fold #0.\n",
      "\n",
      "Train/Test model FCNN on Fold #1.\n",
      "\n",
      "Train/Test model FCNN on Fold #2.\n",
      "\n",
      "Train/Test model FCNN on Fold #3.\n",
      "\n",
      "Train/Test model FCNN on Fold #4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "File: Generated\\MathFeature_setting1\\Datasets\\Setting1\\Yeast\\nucleosomes_vs_linkers_yeast_ALL-v2.csv\n",
      "Nucleosomi: 1880\n",
      "Linker: 1740\n",
      "MODEL!\n",
      "\n",
      "Train/Test model FCNN on Fold #0.\n",
      "\n",
      "Train/Test model FCNN on Fold #1.\n",
      "\n",
      "Train/Test model FCNN on Fold #2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model FCNN on Fold #3.\n",
      "\n",
      "Train/Test model FCNN on Fold #4.\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "error_list = []\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Encoding_Type\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_setting_path):\n",
    "    for file in files:\n",
    "        if (os.path.splitext(file)[-1] == datafile_extensions) & (file.split(\".\")[0].split(\"_\")[-1] == \"ALL-v2\"):\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "                encoding_type = file.split(\".\")[0].split(\"_\")[-1]\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### read the current file\n",
    "                ##################################################################################\n",
    "\n",
    "                input_file_full_path = os.path.join(root, file)\n",
    "                sequences_df = pd.read_csv(input_file_full_path, header = \"infer\", low_memory=False)\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### extract data from the current dataframe file\n",
    "                ##################################################################################\n",
    "\n",
    "                sequences_df[\"class\"] = np.where(sequences_df[sequences_df.columns[0]].str.contains(\"nucleosomal\"), 1, 0)\n",
    "\n",
    "                print(\"\\n======================================================================\")\n",
    "                print(\"\\nFile: \"+os.path.join(root, file))\n",
    "                print(\"Nucleosomi: \"+str(sum(sequences_df[\"class\"])))\n",
    "                print(\"Linker: \"+str(len(sequences_df) - sum(sequences_df[\"class\"])))\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### Generate Folds from dataset, and store to file\n",
    "                ##################################################################################\n",
    "\n",
    "                ## create the features and labels datasets for the training\n",
    "                labels = np.array(sequences_df[\"class\"])\n",
    "                # print(\"label extracted\")\n",
    "                features = sequences_df.drop(\"nameseq\", axis = 1).drop(\"class\", axis = 1).values\n",
    "                # print(\"features extracted\")\n",
    "                features = features.astype(np.float32)\n",
    "                # print(\"features type casted\")\n",
    "                features = features.reshape(features.shape + (1,))\n",
    "                \n",
    "                # input_size = (features.shape[1], features.shape[2])\n",
    "                \n",
    "                ## Parameters to Read/Write the k-fold dataset to file\n",
    "                foldPath = os.path.join(result_output_path, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "                foldName = file.split(\".\")[0]+\"_{}fold\".format(n_fold)+\".pickle\"\n",
    "\n",
    "                ##### ADDITIONAL CHANGES - USE PREVIOUS GENERATED FOLDS IF AVAILABLE\n",
    "\n",
    "                if(os.path.isfile(os.path.join(foldPath, foldName))):\n",
    "                    folds = pickle.load(open(os.path.join(foldPath, foldName), \"rb\"))\n",
    "                else:\n",
    "                    ## Generate the k-fold dataset\n",
    "                    folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "                    if(not os.path.isdir(foldPath)):\n",
    "                        os.makedirs(foldPath)\n",
    "                    pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "                \n",
    "                for modelName in modelNames:\n",
    "\n",
    "                    ## Create and set directory to save model\n",
    "                    modelPath = os.path.join(result_output_path, current_dataset_variety, \"{}fold\".format(n_fold), \"models\", modelName)\n",
    "                    if(not os.path.isdir(modelPath)):\n",
    "                        os.makedirs(modelPath)\n",
    "\n",
    "                    ## fold counter\n",
    "                    i = 0\n",
    "\n",
    "                    for fold in folds:\n",
    "\n",
    "                        print(\"\\nTrain/Test model \"+modelName+\" on Fold #\"+str(i)+\".\")\n",
    "\n",
    "                        ## Generate model using function\n",
    "                        # model = RandomForestClassifier(n_estimators=50, \n",
    "                        #                                criterion='entropy', \n",
    "                        #                                bootstrap=True,\n",
    "                        #                                oob_score=True, \n",
    "                        #                                warm_start = True)\n",
    "                        \n",
    "                        # model = ExtraTreesClassifier(n_estimators=50, \n",
    "                        #                              criterion='gini', \n",
    "                        #                              bootstrap=True,\n",
    "                        #                              oob_score=True, \n",
    "                        #                              warm_start = True)\n",
    "                        \n",
    "                        # model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "                        \n",
    "                        # model = SVC(C = 2,\n",
    "                        #             kernel = \"rbf\",\n",
    "                        #             # degree = 5, # only for kernel = poly\n",
    "                        #             gamma = \"scale\", # only for kernel = rbf/poly/sigmoid\n",
    "                        #             max_iter = -1)\n",
    "                        \n",
    "                        # model.fit(X = fold[\"X_train\"], y = fold[\"y_train\"])\n",
    "                        \n",
    "                        # model_filename = \"{}_fold{}_model.pickle\".format(encoding_type, i)\n",
    "                        \n",
    "                        # model_file_obj = open(os.path.join(modelPath, model_filename), 'wb')\n",
    "                        # pickle.dump(model, model_file_obj)\n",
    "                        # model_file_obj.close()\n",
    "                        \n",
    "                        ## Generate model using function\n",
    "                        # model = Conv_LSTM_DLNN(input_shape = input_size, \n",
    "                        #                        conv_filters_per_layer = 50, kernel_length = kernel_length, \n",
    "                        #                        lstm_decode_units = 50,\n",
    "                        #                        prob = 0.5, \n",
    "                        #                        learn_rate = 0.001, loss = 'binary_crossentropy', metrics = None, \n",
    "                        #                        max_pool_width = 2, max_pool_stride = 2, \n",
    "                        #                        dense_decode_units = 150)\n",
    "                        \n",
    "                        input_size = (fold[\"X_train\"].shape[1],)\n",
    "                        \n",
    "                        ## Generate model using function\n",
    "                        model = FCNN(input_shape=input_size, \n",
    "                                     dense_decode_units_1 = input_size[0],\n",
    "                                     dense_decode_units_2 = 150,\n",
    "                                     max_pool_stride = 2, max_pool_width = 2,\n",
    "                                     learn_rate = 0.001, prob = 0.5, loss = 'binary_crossentropy', metrics = None)\n",
    "                        \n",
    "                        ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "#                         modelCallbacks = [\n",
    "#                             tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(modelName, i)),\n",
    "#                                                                monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "#                                                                save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "#                             tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, \n",
    "#                                                              mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "#                         ]\n",
    "                        modelCallbacks = [\n",
    "                            tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(modelName, i)),\n",
    "                                                               monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "                                                               save_weights_only = False, mode = 'auto', save_freq = 'epoch')\n",
    "                        ]\n",
    "                        model.fit(x = fold[\"X_train\"].reshape(fold[\"X_train\"].shape[0], fold[\"X_train\"].shape[1]), \n",
    "                                  y = fold[\"y_train\"], batch_size = batch_size, epochs = epochs, verbose = 0, \n",
    "                                  callbacks = modelCallbacks, validation_data = (fold[\"X_test\"].reshape(fold[\"X_test\"].shape[0], fold[\"X_test\"].shape[1]), \n",
    "                                                                                 fold[\"y_test\"]))\n",
    "\n",
    "                        ##################################################################################\n",
    "                        ##### Prediction and metrics for TRAIN dataset\n",
    "                        ##################################################################################\n",
    "\n",
    "                        y_pred = model.predict(fold[\"X_train\"].reshape(fold[\"X_train\"].shape[0], fold[\"X_train\"].shape[1]))\n",
    "                        label_pred = pred2label(y_pred)\n",
    "                        # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                        acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "                        prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "                        conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "                        if(conf[0][0]+conf[1][0]):\n",
    "                            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                        else:\n",
    "                            sens = 0.0\n",
    "                        if(conf[1][1]+conf[0][1]):\n",
    "                            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                        else:\n",
    "                            spec = 0.0\n",
    "                        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                        else:\n",
    "                            mcc= 0.0\n",
    "                        fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "                        auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "                        evaluations[\"Model\"].append(modelName)\n",
    "                        evaluations[\"Encoding_Type\"].append(encoding_type)\n",
    "                        evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                        evaluations[\"Fold\"].append(i)\n",
    "                        evaluations[\"Train_Test\"].append(\"Train\")\n",
    "                        evaluations[\"Accuracy\"].append(acc)\n",
    "                        evaluations[\"Precision\"].append(prec)\n",
    "                        evaluations[\"TPR\"].append(tpr)\n",
    "                        evaluations[\"FPR\"].append(fpr)\n",
    "                        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                        evaluations[\"AUC\"].append(auc)\n",
    "                        evaluations[\"Sensitivity\"].append(sens)\n",
    "                        evaluations[\"Specificity\"].append(spec)\n",
    "                        evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "                        ##################################################################################\n",
    "                        ##### Prediction and metrics for TEST dataset\n",
    "                        ##################################################################################\n",
    "\n",
    "                        y_pred = model.predict(fold[\"X_test\"].reshape(fold[\"X_test\"].shape[0], fold[\"X_test\"].shape[1]))\n",
    "                        label_pred = pred2label(y_pred)\n",
    "                        # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                        acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "                        prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "                        conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "                        if(conf[0][0]+conf[1][0]):\n",
    "                            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                        else:\n",
    "                            sens = 0.0\n",
    "                        if(conf[1][1]+conf[0][1]):\n",
    "                            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                        else:\n",
    "                            spec = 0.0\n",
    "                        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                        else:\n",
    "                            mcc= 0.0\n",
    "                        fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "                        auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "                        evaluations[\"Model\"].append(modelName)\n",
    "                        evaluations[\"Encoding_Type\"].append(encoding_type)\n",
    "                        evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                        evaluations[\"Fold\"].append(i)\n",
    "                        evaluations[\"Train_Test\"].append(\"Test\")\n",
    "                        evaluations[\"Accuracy\"].append(acc)\n",
    "                        evaluations[\"Precision\"].append(prec)\n",
    "                        evaluations[\"TPR\"].append(tpr)\n",
    "                        evaluations[\"FPR\"].append(fpr)\n",
    "                        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                        evaluations[\"AUC\"].append(auc)\n",
    "                        evaluations[\"Sensitivity\"].append(sens)\n",
    "                        evaluations[\"Specificity\"].append(spec)\n",
    "                        evaluations[\"MCC\"].append(mcc)\n",
    "                        \n",
    "                        i = i+1\n",
    "                        \n",
    "            except Exception as error:\n",
    "                error_list.append((input_file_full_path, error))\n",
    "                \n",
    "##################################################################################\n",
    "##### Dump evaluations to a file\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(result_output_path, \"_Evaluation_All_Datasets\", \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "pickle.dump(evaluations,\n",
    "            open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelNames[0])), \"wb\"))\n",
    "\n",
    "##################################################################################\n",
    "##### Dump exceptions to a file\n",
    "##################################################################################\n",
    "\n",
    "pickle.dump(error_list,\n",
    "            open(os.path.join(result_output_path, \"exceptions.pickle\"), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Parameters used only in this section\n",
    "# ##################################################################################\n",
    "\n",
    "# n_fold = 10\n",
    "\n",
    "# expName = \"MathFeature_setting1_kgap_fickett\"\n",
    "# outPath = \"Generated\"\n",
    "# setting = \"Setting1\"\n",
    "# output_path = \"Results\"\n",
    "\n",
    "# RandomForest, FCNN, DLNN - for Results_ALL\n",
    "\n",
    "modelNames = [\"DLNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, output_path, setting, \"_Evaluation_All_Datasets\", \"{}fold\".format(n_fold))\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelNames[0])), \"rb\"))\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Encoding_Type</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.503573, 0.5035729]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.503573, 0.5035729]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5028789, 0.50287896]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5028789, 0.50287896]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5038693, 0.50386924]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5038693, 0.50386924]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5035467, 0.5035467]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5035467, 0.5035467]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5028775, 0.5028774]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5028775, 0.5028774]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.504106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4973785, 0.49737847]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.503382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4973785, 0.49737847]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.504106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4962904, 0.4962904]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.503382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4962904, 0.4962904]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.503865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4965659, 0.49656597]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4965659, 0.49656597]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.503865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4975703, 0.49757022]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4975703, 0.49757022]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.503865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4967637, 0.49676368]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Elegans</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4967637, 0.49676368]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4984875, 0.4984874]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4984875, 0.4984874]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4987838, 0.49878377]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4987838, 0.49878377]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4976254, 0.49762535]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4976254, 0.49762535]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.502870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4985622, 0.4985622]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.503282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4985622, 0.4985622]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.502870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4980595, 0.49805945]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Homo_Sapiens</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.503282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.4980595, 0.49805945]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5118186, 0.5118187]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5118186, 0.5118187]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5112436, 0.5112436]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5112436, 0.5112436]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5115805, 0.51158047]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5115805, 0.51158047]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5126958, 0.5126958]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5126958, 0.5126958]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5124742, 0.5124742]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>DLNN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[1.5124742, 0.5124742]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Encoding_Type       Dataset  Fold Train_Test  Accuracy  Precision  \\\n",
       "0   DLNN           ALL    Drosophila     0      Train  0.504348   0.504348   \n",
       "1   DLNN           ALL    Drosophila     0       Test  0.504348   0.504348   \n",
       "2   DLNN           ALL    Drosophila     1      Train  0.504348   0.504348   \n",
       "3   DLNN           ALL    Drosophila     1       Test  0.504348   0.504348   \n",
       "4   DLNN           ALL    Drosophila     2      Train  0.504348   0.504348   \n",
       "5   DLNN           ALL    Drosophila     2       Test  0.504348   0.504348   \n",
       "6   DLNN           ALL    Drosophila     3      Train  0.504348   0.504348   \n",
       "7   DLNN           ALL    Drosophila     3       Test  0.504348   0.504348   \n",
       "8   DLNN           ALL    Drosophila     4      Train  0.504348   0.504348   \n",
       "9   DLNN           ALL    Drosophila     4       Test  0.504348   0.504348   \n",
       "10  DLNN           ALL       Elegans     0      Train  0.504106   0.000000   \n",
       "11  DLNN           ALL       Elegans     0       Test  0.503382   0.000000   \n",
       "12  DLNN           ALL       Elegans     1      Train  0.504106   0.000000   \n",
       "13  DLNN           ALL       Elegans     1       Test  0.503382   0.000000   \n",
       "14  DLNN           ALL       Elegans     2      Train  0.503865   0.000000   \n",
       "15  DLNN           ALL       Elegans     2       Test  0.504348   0.000000   \n",
       "16  DLNN           ALL       Elegans     3      Train  0.503865   0.000000   \n",
       "17  DLNN           ALL       Elegans     3       Test  0.504348   0.000000   \n",
       "18  DLNN           ALL       Elegans     4      Train  0.503865   0.000000   \n",
       "19  DLNN           ALL       Elegans     4       Test  0.504348   0.000000   \n",
       "20  DLNN           ALL  Homo_Sapiens     0      Train  0.503007   0.000000   \n",
       "21  DLNN           ALL  Homo_Sapiens     0       Test  0.502732   0.000000   \n",
       "22  DLNN           ALL  Homo_Sapiens     1      Train  0.503007   0.000000   \n",
       "23  DLNN           ALL  Homo_Sapiens     1       Test  0.502732   0.000000   \n",
       "24  DLNN           ALL  Homo_Sapiens     2      Train  0.503007   0.000000   \n",
       "25  DLNN           ALL  Homo_Sapiens     2       Test  0.502732   0.000000   \n",
       "26  DLNN           ALL  Homo_Sapiens     3      Train  0.502870   0.000000   \n",
       "27  DLNN           ALL  Homo_Sapiens     3       Test  0.503282   0.000000   \n",
       "28  DLNN           ALL  Homo_Sapiens     4      Train  0.502870   0.000000   \n",
       "29  DLNN           ALL  Homo_Sapiens     4       Test  0.503282   0.000000   \n",
       "30  DLNN           ALL         Yeast     0      Train  0.519337   0.519337   \n",
       "31  DLNN           ALL         Yeast     0       Test  0.519337   0.519337   \n",
       "32  DLNN           ALL         Yeast     1      Train  0.519337   0.519337   \n",
       "33  DLNN           ALL         Yeast     1       Test  0.519337   0.519337   \n",
       "34  DLNN           ALL         Yeast     2      Train  0.519337   0.519337   \n",
       "35  DLNN           ALL         Yeast     2       Test  0.519337   0.519337   \n",
       "36  DLNN           ALL         Yeast     3      Train  0.519337   0.519337   \n",
       "37  DLNN           ALL         Yeast     3       Test  0.519337   0.519337   \n",
       "38  DLNN           ALL         Yeast     4      Train  0.519337   0.519337   \n",
       "39  DLNN           ALL         Yeast     4       Test  0.519337   0.519337   \n",
       "\n",
       "           TPR         FPR       TPR_FPR_Thresholds  AUC  Sensitivity  \\\n",
       "0   [0.0, 1.0]  [0.0, 1.0]    [1.503573, 0.5035729]  0.5     0.000000   \n",
       "1   [0.0, 1.0]  [0.0, 1.0]    [1.503573, 0.5035729]  0.5     0.000000   \n",
       "2   [0.0, 1.0]  [0.0, 1.0]  [1.5028789, 0.50287896]  0.5     0.000000   \n",
       "3   [0.0, 1.0]  [0.0, 1.0]  [1.5028789, 0.50287896]  0.5     0.000000   \n",
       "4   [0.0, 1.0]  [0.0, 1.0]  [1.5038693, 0.50386924]  0.5     0.000000   \n",
       "5   [0.0, 1.0]  [0.0, 1.0]  [1.5038693, 0.50386924]  0.5     0.000000   \n",
       "6   [0.0, 1.0]  [0.0, 1.0]   [1.5035467, 0.5035467]  0.5     0.000000   \n",
       "7   [0.0, 1.0]  [0.0, 1.0]   [1.5035467, 0.5035467]  0.5     0.000000   \n",
       "8   [0.0, 1.0]  [0.0, 1.0]   [1.5028775, 0.5028774]  0.5     0.000000   \n",
       "9   [0.0, 1.0]  [0.0, 1.0]   [1.5028775, 0.5028774]  0.5     0.000000   \n",
       "10  [0.0, 1.0]  [0.0, 1.0]  [1.4973785, 0.49737847]  0.5     0.504106   \n",
       "11  [0.0, 1.0]  [0.0, 1.0]  [1.4973785, 0.49737847]  0.5     0.503382   \n",
       "12  [0.0, 1.0]  [0.0, 1.0]   [1.4962904, 0.4962904]  0.5     0.504106   \n",
       "13  [0.0, 1.0]  [0.0, 1.0]   [1.4962904, 0.4962904]  0.5     0.503382   \n",
       "14  [0.0, 1.0]  [0.0, 1.0]  [1.4965659, 0.49656597]  0.5     0.503865   \n",
       "15  [0.0, 1.0]  [0.0, 1.0]  [1.4965659, 0.49656597]  0.5     0.504348   \n",
       "16  [0.0, 1.0]  [0.0, 1.0]  [1.4975703, 0.49757022]  0.5     0.503865   \n",
       "17  [0.0, 1.0]  [0.0, 1.0]  [1.4975703, 0.49757022]  0.5     0.504348   \n",
       "18  [0.0, 1.0]  [0.0, 1.0]  [1.4967637, 0.49676368]  0.5     0.503865   \n",
       "19  [0.0, 1.0]  [0.0, 1.0]  [1.4967637, 0.49676368]  0.5     0.504348   \n",
       "20  [0.0, 1.0]  [0.0, 1.0]   [1.4984875, 0.4984874]  0.5     0.503007   \n",
       "21  [0.0, 1.0]  [0.0, 1.0]   [1.4984875, 0.4984874]  0.5     0.502732   \n",
       "22  [0.0, 1.0]  [0.0, 1.0]  [1.4987838, 0.49878377]  0.5     0.503007   \n",
       "23  [0.0, 1.0]  [0.0, 1.0]  [1.4987838, 0.49878377]  0.5     0.502732   \n",
       "24  [0.0, 1.0]  [0.0, 1.0]  [1.4976254, 0.49762535]  0.5     0.503007   \n",
       "25  [0.0, 1.0]  [0.0, 1.0]  [1.4976254, 0.49762535]  0.5     0.502732   \n",
       "26  [0.0, 1.0]  [0.0, 1.0]   [1.4985622, 0.4985622]  0.5     0.502870   \n",
       "27  [0.0, 1.0]  [0.0, 1.0]   [1.4985622, 0.4985622]  0.5     0.503282   \n",
       "28  [0.0, 1.0]  [0.0, 1.0]  [1.4980595, 0.49805945]  0.5     0.502870   \n",
       "29  [0.0, 1.0]  [0.0, 1.0]  [1.4980595, 0.49805945]  0.5     0.503282   \n",
       "30  [0.0, 1.0]  [0.0, 1.0]   [1.5118186, 0.5118187]  0.5     0.000000   \n",
       "31  [0.0, 1.0]  [0.0, 1.0]   [1.5118186, 0.5118187]  0.5     0.000000   \n",
       "32  [0.0, 1.0]  [0.0, 1.0]   [1.5112436, 0.5112436]  0.5     0.000000   \n",
       "33  [0.0, 1.0]  [0.0, 1.0]   [1.5112436, 0.5112436]  0.5     0.000000   \n",
       "34  [0.0, 1.0]  [0.0, 1.0]  [1.5115805, 0.51158047]  0.5     0.000000   \n",
       "35  [0.0, 1.0]  [0.0, 1.0]  [1.5115805, 0.51158047]  0.5     0.000000   \n",
       "36  [0.0, 1.0]  [0.0, 1.0]   [1.5126958, 0.5126958]  0.5     0.000000   \n",
       "37  [0.0, 1.0]  [0.0, 1.0]   [1.5126958, 0.5126958]  0.5     0.000000   \n",
       "38  [0.0, 1.0]  [0.0, 1.0]   [1.5124742, 0.5124742]  0.5     0.000000   \n",
       "39  [0.0, 1.0]  [0.0, 1.0]   [1.5124742, 0.5124742]  0.5     0.000000   \n",
       "\n",
       "    Specificity  MCC  \n",
       "0      0.504348  0.0  \n",
       "1      0.504348  0.0  \n",
       "2      0.504348  0.0  \n",
       "3      0.504348  0.0  \n",
       "4      0.504348  0.0  \n",
       "5      0.504348  0.0  \n",
       "6      0.504348  0.0  \n",
       "7      0.504348  0.0  \n",
       "8      0.504348  0.0  \n",
       "9      0.504348  0.0  \n",
       "10     0.000000  0.0  \n",
       "11     0.000000  0.0  \n",
       "12     0.000000  0.0  \n",
       "13     0.000000  0.0  \n",
       "14     0.000000  0.0  \n",
       "15     0.000000  0.0  \n",
       "16     0.000000  0.0  \n",
       "17     0.000000  0.0  \n",
       "18     0.000000  0.0  \n",
       "19     0.000000  0.0  \n",
       "20     0.000000  0.0  \n",
       "21     0.000000  0.0  \n",
       "22     0.000000  0.0  \n",
       "23     0.000000  0.0  \n",
       "24     0.000000  0.0  \n",
       "25     0.000000  0.0  \n",
       "26     0.000000  0.0  \n",
       "27     0.000000  0.0  \n",
       "28     0.000000  0.0  \n",
       "29     0.000000  0.0  \n",
       "30     0.519337  0.0  \n",
       "31     0.519337  0.0  \n",
       "32     0.519337  0.0  \n",
       "33     0.519337  0.0  \n",
       "34     0.519337  0.0  \n",
       "35     0.519337  0.0  \n",
       "36     0.519337  0.0  \n",
       "37     0.519337  0.0  \n",
       "38     0.519337  0.0  \n",
       "39     0.519337  0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Dataset\",\n",
    "                                                 \"Encoding_Type\",\n",
    "                                                 \"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "# Eval_Train = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(3), ['Train'])]\n",
    "# Eval_Test = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(3), ['Test'])]\n",
    "\n",
    "# datasets = np.unique(evaluations_df_grouped.index.get_level_values(0))\n",
    "\n",
    "# evaluations_df_grouped = evaluations_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Available :  ['Accuracy', 'Precision', 'AUC', 'Sensitivity', 'Specificity', 'MCC']\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Decide on metric to visualize\n",
    "##################################################################################\n",
    "\n",
    "print(\"Metrics Available : \", list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Visualize with a multiple Bar chart\n",
    "##################################################################################\n",
    "\n",
    "# df = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), [dataset_to_print])]\n",
    "# df = evaluations_df_grouped.reset_index(level=['Dataset', 'Encoding_Type', 'Train_Test'])\n",
    "df = evaluations_df_grouped.reset_index()\n",
    "\n",
    "# Some boilerplate to initialise things\n",
    "sns.set()\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "# Draw the bars\n",
    "ax = sns.barplot(data=df, x=\"Dataset\", y=metric_to_plot, hue=\"Train_Test\")\n",
    "\n",
    "# Customise some display properties\n",
    "ax.set_title(metric_to_plot)\n",
    "ax.grid(color='#cccccc')\n",
    "ax.set_ylabel(metric_to_plot)\n",
    "ax.set_xlabel(\"Dataset\")\n",
    "ax.set_xticklabels(df[\"Dataset\"].unique().astype(str), rotation='vertical')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height()*100, '.4f'),\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                size=15,\n",
    "                xytext = (0, -12), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "##############################\n",
    "\n",
    "# Ask Matplotlib to show it\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Iteratively generate comparison plot using every metric\n",
    "##################################################################################\n",
    "\n",
    "for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "    # df = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), [dataset_to_print])]\n",
    "    # df = evaluations_df_grouped.reset_index(level=['Dataset', 'Encoding_Type', 'Train_Test'])\n",
    "    df = evaluations_df_grouped.reset_index()\n",
    "\n",
    "    # Some boilerplate to initialise things\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(20,8))\n",
    "\n",
    "    # Draw the bars\n",
    "    ax = sns.barplot(data=df, x=\"Dataset\", y=metric_to_plot, hue=\"Train_Test\")\n",
    "\n",
    "    # Customise some display properties\n",
    "    ax.set_title(metric_to_plot)\n",
    "    ax.grid(color='#cccccc')\n",
    "    ax.set_ylabel(metric_to_plot)\n",
    "    ax.set_xlabel(\"Dataset\")\n",
    "    ax.set_xticklabels(df[\"Dataset\"].unique().astype(str), rotation='vertical')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height()*100, '.4f'),\n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    size=15,\n",
    "                    xytext = (0, -12), \n",
    "                    textcoords = 'offset points')\n",
    "        \n",
    "    plt.savefig(os.path.join(evalPath, \"{}_{}_Comparison\".format(metric_to_plot, modelNames[0])))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
