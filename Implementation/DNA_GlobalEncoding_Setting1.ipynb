{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from DNA_Encoding import DNA_Encoding\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators = 100, random_state = 42, criterion = \"gini\")\n",
    "\n",
    "# model_random = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# # model_random.fit(fold[\"X_train\"], fold[\"y_train\"].reshape(fold[\"y_train\"].shape[0]))\n",
    "# model_random.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 10\n",
    "shuffle = False\n",
    "seed = None\n",
    "\n",
    "# expName = \"embedReads_setting1_DNAGlobalEncoding_backup\"\n",
    "expName = \"embedReads_setting1_DNAGlobalEncoding\"\n",
    "\n",
    "dataset_path = \"CORENup-Datasets\\\\Datasets\"\n",
    "setting = \"Setting1\"\n",
    "\n",
    "outPath = \"Generated\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "modelName = \"RandomForest\"\n",
    "\n",
    "dataset_setting_path = os.path.join(dataset_path, setting)\n",
    "\n",
    "obj_DNA_Encoding = DNA_Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "# def pred2label(y_pred):\n",
    "#     y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "File: CORENup-Datasets\\Datasets\\Setting1\\Drosophila\\nucleosomes_vs_linkers_melanogaster.fas\n",
      "Nucleosomi: 2900\n",
      "Linker: 2850\n",
      "\n",
      "Train/Test model RandomForest on Fold #0.\n",
      "\n",
      "Train/Test model RandomForest on Fold #1.\n",
      "\n",
      "Train/Test model RandomForest on Fold #2.\n",
      "\n",
      "Train/Test model RandomForest on Fold #3.\n",
      "\n",
      "Train/Test model RandomForest on Fold #4.\n",
      "\n",
      "Train/Test model RandomForest on Fold #5.\n",
      "\n",
      "Train/Test model RandomForest on Fold #6.\n",
      "\n",
      "Train/Test model RandomForest on Fold #7.\n",
      "\n",
      "Train/Test model RandomForest on Fold #8.\n",
      "\n",
      "Train/Test model RandomForest on Fold #9.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "File: CORENup-Datasets\\Datasets\\Setting1\\Elegans\\nucleosomes_vs_linkers_elegans.fas\n",
      "Nucleosomi: 2567\n",
      "Linker: 2608\n",
      "\n",
      "Train/Test model RandomForest on Fold #0.\n",
      "\n",
      "Train/Test model RandomForest on Fold #1.\n",
      "\n",
      "Train/Test model RandomForest on Fold #2.\n",
      "\n",
      "Train/Test model RandomForest on Fold #3.\n",
      "\n",
      "Train/Test model RandomForest on Fold #4.\n",
      "\n",
      "Train/Test model RandomForest on Fold #5.\n",
      "\n",
      "Train/Test model RandomForest on Fold #6.\n",
      "\n",
      "Train/Test model RandomForest on Fold #7.\n",
      "\n",
      "Train/Test model RandomForest on Fold #8.\n",
      "\n",
      "Train/Test model RandomForest on Fold #9.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3d84e1c56ffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mlinker_encoded_List\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfasta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfastaSequences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfasta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"nucleosomal\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Bio\\SeqIO\\Interfaces.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_close_stream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Bio\\SeqIO\\FastaIO.py\u001b[0m in \u001b[0;36miterate\u001b[1;34m(self, handle)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mSeqRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdescr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSimpleFastaParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                     \u001b[0mfirst_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Bio\\SeqIO\\FastaIO.py\u001b[0m in \u001b[0;36mSimpleFastaParser\u001b[1;34m(handle)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# when not opened in universal read lines mode)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\">\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Kernel_Length\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_setting_path):\n",
    "    for file in files:\n",
    "        \n",
    "        current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "        \n",
    "        ##################################################################################\n",
    "        ##### read the current file\n",
    "        ##################################################################################\n",
    "\n",
    "        openFile = open(os.path.join(root, file))\n",
    "        fastaSequences = SeqIO.parse(openFile, \"fasta\")\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### extract data from the current fasta file\n",
    "        ##################################################################################\n",
    "        \n",
    "        nucleosomal_List = []\n",
    "        linker_List = []\n",
    "        nucleosomal_encoded_List = []\n",
    "        linker_encoded_List = []\n",
    "\n",
    "        for fasta in fastaSequences: \n",
    "            name, sequence = fasta.id, str(fasta.seq)\n",
    "            if \"nucleosomal\" in name:\n",
    "                nucleosomal_List.append(sequence)\n",
    "                aus_seq = DNA_Encoding.GlobalEncoding(self = obj_DNA_Encoding, seq = sequence)\n",
    "                if(len(aus_seq) != 0):\n",
    "                    nucleosomal_encoded_List.append(aus_seq)\n",
    "            else:\n",
    "                linker_List.append(sequence)\n",
    "                aus_seq = DNA_Encoding.GlobalEncoding(self = obj_DNA_Encoding, seq = sequence)\n",
    "                if(len(aus_seq) != 0):\n",
    "                    linker_encoded_List.append(aus_seq)\n",
    "\n",
    "        print(\"\\n======================================================================\")\n",
    "        print(\"\\nFile: \"+os.path.join(root, file))\n",
    "        print(\"Nucleosomi: \"+str(len(nucleosomal_encoded_List)))\n",
    "        print(\"Linker: \"+str(len(linker_encoded_List)))\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Generate Folds from dataset, and store to file\n",
    "        ##################################################################################\n",
    "\n",
    "        ## create the features and labels datasets for the training\n",
    "        # input_size = (len(nucleosomal_encoded_List[1]), 4)\n",
    "        labels = np.concatenate((np.ones((len(nucleosomal_encoded_List), 1), dtype=np.float32), np.zeros((len(linker_encoded_List), 1), dtype=np.float32)), axis=0)\n",
    "        features = np.concatenate((nucleosomal_encoded_List,linker_encoded_List), 0)\n",
    "\n",
    "        ## Generate the k-fold dataset\n",
    "        folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "        ## Write the k-fold dataset to file\n",
    "        foldPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "\n",
    "        ##### ADDITIONAL CHANGES - USE PREVIOUS GENERATED FOLDS IF AVAILABLE\n",
    "\n",
    "        if(os.path.isfile(os.path.join(foldPath, foldName))):\n",
    "            folds = pickle.load(open(os.path.join(foldPath, foldName), \"rb\"))\n",
    "        else:\n",
    "            if(not os.path.isdir(foldPath)):\n",
    "                os.makedirs(foldPath)\n",
    "            pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### TRAIN and PREDICT for every Fold, using Random Forest\n",
    "        ##################################################################################\n",
    "\n",
    "        ## Create and set directory to save model\n",
    "        modelPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold), \"models\", modelName)\n",
    "        if(not os.path.isdir(modelPath)):\n",
    "            os.makedirs(modelPath)\n",
    "\n",
    "        ## fold counter\n",
    "        i = 0\n",
    "\n",
    "        for fold in folds:\n",
    "\n",
    "            print(\"\\nTrain/Test model \"+modelName+\" on Fold #\"+str(i)+\".\")\n",
    "\n",
    "            ## Generate model Random Forest\n",
    "            model = RandomForestClassifier(n_estimators = 100, random_state = 42, oob_score = True, criterion = \"gini\")\n",
    "\n",
    "            model.fit(X = fold[\"X_train\"], \n",
    "                      y = fold[\"y_train\"].reshape(fold[\"y_train\"].shape[0]))\n",
    "            \n",
    "            pickle.dump(model, open(os.path.join(modelPath, \"{}_bestModel-fold{}.pkl\".format(modelName, i)), 'wb'))\n",
    "            \n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TRAIN dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_pred = model.predict(fold[\"X_train\"])\n",
    "            #label_pred = pred2label(y_pred)\n",
    "            label_pred = y_pred\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(modelName)\n",
    "            evaluations[\"Kernel_Length\"].append(\"\")\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Train\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TEST dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_pred = model.predict(fold[\"X_test\"])\n",
    "            # label_pred = pred2label(y_pred)\n",
    "            label_pred = y_pred\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(modelName)\n",
    "            evaluations[\"Kernel_Length\"].append(\"\")\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Test\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            i = i+1\n",
    "            del model\n",
    "\n",
    "##################################################################################\n",
    "##### Dump evaluations to a file\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "pickle.dump(evaluations,\n",
    "            open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelName)), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Parameters used only in this section\n",
    "# ##################################################################################\n",
    "\n",
    "# n_fold = 10\n",
    "# expName = \"embedReads_setting1_DNAGlobalEncoding\"\n",
    "# outPath = \"Generated\"\n",
    "\n",
    "# modelNames = [\"RandomForest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelName.format(\"all\"))), \"rb\"))\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Dataset\", \n",
    "                                                 \"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "RF_Train = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(2), ['Train'])]\n",
    "RF_Test = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(2), ['Test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Decide on metric to visualize\n",
    "##################################################################################\n",
    "\n",
    "print(\"Metrics Available : \")\n",
    "print(list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Visualize with a multiple Bar chart\n",
    "##################################################################################\n",
    "\n",
    "x = np.arange(len(RF_Train[metric_to_plot]))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,6))\n",
    "rects1 = ax.bar(x - (1.5*(width/2)), round(RF_Train[metric_to_plot]*100, 3), width, label='Random Forest, Train')\n",
    "rects3 = ax.bar(x + (1.5*(width/2)), round(RF_Test[metric_to_plot]*100, 3), width, label='Random Forest, Test')\n",
    "\n",
    "## Custom y-axis tick labels\n",
    "ax.set_ylabel(metric_to_plot)\n",
    "ax.set_ylim([max((math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, 0), \n",
    "            max((math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10, 0)])\n",
    "# ax.set_ylim([80, 105])\n",
    "\n",
    "## Custom x-axis tick labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(RF_Train.index.get_level_values(0))\n",
    "# ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "#                         zip(DLNN_CORENup_Train.index.get_level_values(0),DLNN_CORENup_Train.index.get_level_values(1))],\n",
    "#                   rotation=30)\n",
    "# ax.set_xticklabels([a + \"_\" + b.split(\"_\")[1] for a, b in zip(RF_Train.index.get_level_values(0), RF_Train.index.get_level_values(1))],\n",
    "#                   rotation=30)\n",
    "\n",
    "\n",
    "ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\", \n",
    "                    ha='center', va='bottom', rotation=90)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Iteratively generate comparison plot using every metric\n",
    "##################################################################################\n",
    "\n",
    "for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "    x = np.arange(len(RF_Train[metric_to_plot]))\n",
    "    width = 0.15\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(17,6))\n",
    "    rects1 = ax.bar(x - (1.5*(width/2)), round(RF_Train[metric_to_plot]*100, 3), width, label='Random Forest, Train')\n",
    "    rects3 = ax.bar(x + (1.5*(width/2)), round(RF_Test[metric_to_plot]*100, 3), width, label='Random Forest, Test')\n",
    "\n",
    "    ## Custom y-axis tick labels\n",
    "    ax.set_ylabel(metric_to_plot)\n",
    "    ax.set_ylim([max((math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, 0), \n",
    "                max((math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10, 0)])\n",
    "    # ax.set_ylim([80, 105])\n",
    "\n",
    "    ## Custom x-axis tick labels\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(RF_Train.index.get_level_values(0))\n",
    "    # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "    #                         zip(DLNN_CORENup_Train.index.get_level_values(0),DLNN_CORENup_Train.index.get_level_values(1))],\n",
    "    #                   rotation=30)\n",
    "    # ax.set_xticklabels([a + \"_\" + b.split(\"_\")[1] for a, b in zip(RF_Train.index.get_level_values(0), RF_Train.index.get_level_values(1))],\n",
    "    #                   rotation=30)\n",
    "\n",
    "\n",
    "    ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\", \n",
    "                        ha='center', va='bottom', rotation=90)\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects3)\n",
    "    \n",
    "    plt.savefig(os.path.join(evalPath, \"{}_{}_Comparison\".format(metric_to_plot, modelName.format(\"all\"))))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
