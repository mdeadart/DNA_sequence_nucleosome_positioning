{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "expName = \"Test_Run_New_Dataset\"\n",
    "outPath = \"Generated\"\n",
    "\n",
    "modelNames = [\"DLNN_3\", \"DLNN_5\", \"DLNN_CORENup\"]\n",
    "\n",
    "epochs=200\n",
    "batch_size = 64\n",
    "shuffle = False\n",
    "seed = None\n",
    "\n",
    "dataset_path = \"New_Dataset\"\n",
    "setting = \"New_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 22166\n",
      "Testing samples: 6928\n",
      "Evaluation samples: 5542\n",
      "Datapoint shape: [99, 21]\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Load Training, Testing and Evaluation datasets\n",
    "##################################################################################\n",
    "\n",
    "## training data for the models\n",
    "train_X = np.load(\"New_Dataset\\\\New_dataset\\\\train_X.npy\")\n",
    "train_y = np.load(\"New_Dataset\\\\New_dataset\\\\train_y.npy\")\n",
    "\n",
    "## validation dataset for the models\n",
    "eval_X = np.load(\"New_Dataset\\\\New_dataset\\\\eval_X.npy\")\n",
    "eval_y = np.load(\"New_Dataset\\\\New_dataset\\\\eval_y.npy\")\n",
    "\n",
    "## testing dataset for the models\n",
    "test_X = np.load(\"New_Dataset\\\\New_dataset\\\\test_X.npy\")\n",
    "test_y = np.load(\"New_Dataset\\\\New_dataset\\\\test_y.npy\")\n",
    "\n",
    "print(\"Training samples:\",train_X.shape[0])\n",
    "print(\"Testing samples:\",test_X.shape[0])\n",
    "print(\"Evaluation samples:\",eval_X.shape[0])\n",
    "\n",
    "print(\"Datapoint shape:\",[train_X.shape[1], train_X.shape[2]])\n",
    "\n",
    "# Data is already one-hot-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_1d = np.array([xi[0] for xi in train_y])\n",
    "eval_y_1d = np.array([xi[0] for xi in eval_y])\n",
    "test_y_1d = np.array([xi[0] for xi in test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "# ## Build the K-fold from dataset\n",
    "# def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "#     skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "#     kfoldList = []\n",
    "#     for train_index, test_index in skf.split(features, labels):\n",
    "#         X_train, X_test = features[train_index], features[test_index]\n",
    "#         y_train, y_test = labels[train_index], labels[test_index]\n",
    "#         kfoldList.append({\n",
    "#             \"X_train\": X_train,\n",
    "#             \"X_test\": X_test,\n",
    "#             \"y_train\":y_train,\n",
    "#             \"y_test\":y_test\n",
    "#         })\n",
    "#     return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to generate the DLNN-X and CORENup network architectures with parameters\n",
    "##################################################################################\n",
    "\n",
    "def Conv_LSTM_DLNN(input_shape=(150,4), conv_filters_per_layer = 50, kernel_length = 5, lstm_decode_units = 50, \n",
    "                   learn_rate = 0.0003, prob = 0.5, loss = 'binary_crossentropy', metrics = None, max_pool_width = 2, \n",
    "                   max_pool_stride = 2, dense_decode_units = 150):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv1D(conv_filters_per_layer, kernel_length, input_shape = input_shape, \n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(beta), padding=\"same\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.MaxPool1D(pool_size = max_pool_width, strides = max_pool_stride))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2(beta), dropout = 0.1))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras .layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(dense_decode_units, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='sigmoid'))\n",
    "    \n",
    "    #[tf.keras.metrics.binary_accuracy, metrics.precision, metrics.recall, metrics.f1score])\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss, metrics = metrics) \n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def DLNN_CORENup(input_shape = (150,4),\n",
    "                 conv_filters_per_layer_1 = 50, kernel_length_1 = 5, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 2, max_pool_stride_1 = 2, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 50, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 50,  kernel_length_2 = 10, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 2, max_pool_stride_2 = 2, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 370, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0003, loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape = input_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1, input_shape = input_shape, \n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              dropout=0.1)(x1)\n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "\n",
    "    ## Fully connected Layers\n",
    "\n",
    "    y = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    y1 = tf.keras.layers.Dense(dense_decode_units, kernel_regularizer = tf.keras.regularizers.l2(beta), activation = 'relu')(y)\n",
    "    \n",
    "    y1 = tf.keras.layers.Dropout(prob)(y1)\n",
    "    \n",
    "    y1 = tf.keras.layers.Dense(1, kernel_regularizer = tf.keras.regularizers.l2(beta), activation = 'sigmoid')(y1)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=[input1], outputs=y1)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Model DLNN_3 initialized.\n",
      "Epoch 1/200\n",
      "347/347 [==============================] - 2s 7ms/step - loss: 0.8727 - val_loss: 0.7184\n",
      "Epoch 2/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.6902 - val_loss: 0.6244\n",
      "Epoch 3/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.6268 - val_loss: 0.5804\n",
      "Epoch 4/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5942 - val_loss: 0.5519\n",
      "Epoch 5/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5728 - val_loss: 0.5435\n",
      "Epoch 6/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5521 - val_loss: 0.5335\n",
      "Epoch 7/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5410 - val_loss: 0.5172\n",
      "Epoch 8/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5331 - val_loss: 0.5073\n",
      "Epoch 9/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5276 - val_loss: 0.5073\n",
      "Epoch 10/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5221 - val_loss: 0.5017\n",
      "Epoch 11/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5162 - val_loss: 0.4976\n",
      "Epoch 12/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5132 - val_loss: 0.4956\n",
      "Epoch 13/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5112 - val_loss: 0.4898\n",
      "Epoch 14/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5019 - val_loss: 0.4853\n",
      "Epoch 15/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5027 - val_loss: 0.4814\n",
      "Epoch 16/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5006 - val_loss: 0.4872\n",
      "Epoch 17/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4984 - val_loss: 0.4816\n",
      "Epoch 18/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4920 - val_loss: 0.4754\n",
      "Epoch 19/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4902 - val_loss: 0.4719\n",
      "Epoch 20/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4898 - val_loss: 0.4762\n",
      "Epoch 21/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4870 - val_loss: 0.4746\n",
      "Epoch 22/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4863 - val_loss: 0.4832\n",
      "Epoch 23/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4848 - val_loss: 0.4720\n",
      "Epoch 24/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4847 - val_loss: 0.4699\n",
      "Epoch 25/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4803 - val_loss: 0.4705\n",
      "Epoch 26/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4816 - val_loss: 0.4664\n",
      "Epoch 27/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4768 - val_loss: 0.4716\n",
      "Epoch 28/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4774 - val_loss: 0.4617\n",
      "Epoch 29/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4761 - val_loss: 0.4640\n",
      "Epoch 30/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4742 - val_loss: 0.4604\n",
      "Epoch 31/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4747 - val_loss: 0.4633\n",
      "Epoch 32/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4715 - val_loss: 0.4609\n",
      "Epoch 33/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4734 - val_loss: 0.4563\n",
      "Epoch 34/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4690 - val_loss: 0.4702\n",
      "Epoch 35/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4659 - val_loss: 0.4650\n",
      "Epoch 36/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4671 - val_loss: 0.4540\n",
      "Epoch 37/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4689 - val_loss: 0.4614\n",
      "Epoch 38/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4641 - val_loss: 0.4571\n",
      "Epoch 39/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4656 - val_loss: 0.4587\n",
      "Epoch 40/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4639 - val_loss: 0.4561\n",
      "Epoch 41/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4626 - val_loss: 0.4578\n",
      "\n",
      "Model DLNN_3 Trained.\n",
      "Prediction and Evaluation on TRAIN dataset done for DLNN_3 model.\n",
      "Prediction and Evaluation on EVAL dataset done for DLNN_3 model.\n",
      "Prediction and Evaluation on TEST dataset done for DLNN_3 model.\n",
      "===============================================================================================\n",
      "Model DLNN_5 initialized.\n",
      "Epoch 1/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.8657 - val_loss: 0.7168\n",
      "Epoch 2/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.6824 - val_loss: 0.6216\n",
      "Epoch 3/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.6147 - val_loss: 0.5767\n",
      "Epoch 4/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5777 - val_loss: 0.5416\n",
      "Epoch 5/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5544 - val_loss: 0.5213\n",
      "Epoch 6/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5389 - val_loss: 0.5166\n",
      "Epoch 7/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5286 - val_loss: 0.5033\n",
      "Epoch 8/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5210 - val_loss: 0.4934\n",
      "Epoch 9/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5132 - val_loss: 0.4923\n",
      "Epoch 10/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5105 - val_loss: 0.4915\n",
      "Epoch 11/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5027 - val_loss: 0.4848\n",
      "Epoch 12/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.5010 - val_loss: 0.4844\n",
      "Epoch 13/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4936 - val_loss: 0.4787\n",
      "Epoch 14/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4922 - val_loss: 0.4742\n",
      "Epoch 15/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4899 - val_loss: 0.4791\n",
      "Epoch 16/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4857 - val_loss: 0.4751\n",
      "Epoch 17/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4825 - val_loss: 0.4761\n",
      "Epoch 18/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4822 - val_loss: 0.4688\n",
      "Epoch 19/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4779 - val_loss: 0.4730\n",
      "Epoch 20/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4768 - val_loss: 0.4680\n",
      "Epoch 21/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4761 - val_loss: 0.4724\n",
      "Epoch 22/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4744 - val_loss: 0.4653\n",
      "Epoch 23/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4731 - val_loss: 0.4618\n",
      "Epoch 24/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4679 - val_loss: 0.4653\n",
      "Epoch 25/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4709 - val_loss: 0.4560\n",
      "Epoch 26/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4674 - val_loss: 0.4598\n",
      "Epoch 27/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4667 - val_loss: 0.4606\n",
      "Epoch 28/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4588 - val_loss: 0.4546\n",
      "Epoch 29/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4628 - val_loss: 0.4558\n",
      "Epoch 30/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4608 - val_loss: 0.4619\n",
      "Epoch 31/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4579 - val_loss: 0.4561\n",
      "Epoch 32/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4597 - val_loss: 0.4502\n",
      "Epoch 33/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4582 - val_loss: 0.4546\n",
      "Epoch 34/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4561 - val_loss: 0.4587\n",
      "Epoch 35/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4524 - val_loss: 0.4544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "347/347 [==============================] - 2s 5ms/step - loss: 0.4521 - val_loss: 0.4544\n",
      "Epoch 37/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4523 - val_loss: 0.4543\n",
      "\n",
      "Model DLNN_5 Trained.\n",
      "Prediction and Evaluation on TRAIN dataset done for DLNN_5 model.\n",
      "Prediction and Evaluation on EVAL dataset done for DLNN_5 model.\n",
      "Prediction and Evaluation on TEST dataset done for DLNN_5 model.\n",
      "===============================================================================================\n",
      "Model DLNN_CORENup initialized.\n",
      "Epoch 1/200\n",
      "347/347 [==============================] - 3s 8ms/step - loss: 1.1145 - val_loss: 0.8643\n",
      "Epoch 2/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.7923 - val_loss: 0.6996\n",
      "Epoch 3/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.6808 - val_loss: 0.6300\n",
      "Epoch 4/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.6199 - val_loss: 0.5762\n",
      "Epoch 5/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5880 - val_loss: 0.5605\n",
      "Epoch 6/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5662 - val_loss: 0.5386\n",
      "Epoch 7/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5508 - val_loss: 0.5420\n",
      "Epoch 8/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5394 - val_loss: 0.5138\n",
      "Epoch 9/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5300 - val_loss: 0.5082\n",
      "Epoch 10/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5246 - val_loss: 0.5210\n",
      "Epoch 11/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5124 - val_loss: 0.4934\n",
      "Epoch 12/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5109 - val_loss: 0.4958\n",
      "Epoch 13/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5048 - val_loss: 0.4919\n",
      "Epoch 14/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.5013 - val_loss: 0.4948\n",
      "Epoch 15/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4955 - val_loss: 0.4835\n",
      "Epoch 16/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4948 - val_loss: 0.4810\n",
      "Epoch 17/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4897 - val_loss: 0.4814\n",
      "Epoch 18/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4864 - val_loss: 0.4747\n",
      "Epoch 19/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4811 - val_loss: 0.4755\n",
      "Epoch 20/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4817 - val_loss: 0.4856\n",
      "Epoch 21/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4805 - val_loss: 0.4708\n",
      "Epoch 22/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4836 - val_loss: 0.4815\n",
      "Epoch 23/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4789 - val_loss: 0.4652\n",
      "Epoch 24/200\n",
      "347/347 [==============================] - 2s 7ms/step - loss: 0.4759 - val_loss: 0.4647\n",
      "Epoch 25/200\n",
      "347/347 [==============================] - 2s 7ms/step - loss: 0.4759 - val_loss: 0.4620\n",
      "Epoch 26/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4707 - val_loss: 0.4650\n",
      "Epoch 27/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4683 - val_loss: 0.4645\n",
      "Epoch 28/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4732 - val_loss: 0.4678\n",
      "Epoch 29/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4664 - val_loss: 0.4597\n",
      "Epoch 30/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4697 - val_loss: 0.4641\n",
      "Epoch 31/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4670 - val_loss: 0.4638\n",
      "Epoch 32/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4657 - val_loss: 0.4636\n",
      "Epoch 33/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4610 - val_loss: 0.4623\n",
      "Epoch 34/200\n",
      "347/347 [==============================] - 2s 6ms/step - loss: 0.4640 - val_loss: 0.4743\n",
      "\n",
      "Model DLNN_CORENup Trained.\n",
      "Prediction and Evaluation on TRAIN dataset done for DLNN_CORENup model.\n",
      "Prediction and Evaluation on EVAL dataset done for DLNN_CORENup model.\n",
      "Prediction and Evaluation on TEST dataset done for DLNN_CORENup model.\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each model, train and generate generate evaluation metrics\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Kernel_Length\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "input_shape = train_X[0].shape\n",
    "\n",
    "for modelName in modelNames:\n",
    "    if modelName == \"DLNN_CORENup\":\n",
    "        kernel_length = \"5,10\"\n",
    "        model = DLNN_CORENup(input_shape = input_shape)\n",
    "    \n",
    "    else:\n",
    "        kernel_length = int(modelName[-1])\n",
    "        model = Conv_LSTM_DLNN(input_shape = input_shape, conv_filters_per_layer = 50, kernel_length = kernel_length, \n",
    "                               lstm_decode_units = 50, learn_rate = 0.0003, prob = 0.5, loss='binary_crossentropy', \n",
    "                               metrics=None)\n",
    "    \n",
    "    modelPath = os.path.join(outPath, expName, \"Models\")\n",
    "    if(not os.path.isdir(modelPath)):\n",
    "        os.makedirs(modelPath)\n",
    "    \n",
    "    print(\"===============================================================================================\")\n",
    "    print(\"Model\", modelName, \"initialized.\")\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model \n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}.hdf5\".format(modelName)),\n",
    "                                           monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, \n",
    "                                         mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "    ]\n",
    "    model.fit(x = train_X, y = train_y_1d, batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (eval_X, eval_y_1d))\n",
    "    \n",
    "    print(\"\\nModel\", modelName, \"Trained.\")\n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "    \n",
    "    y_pred = model.predict(train_X)\n",
    "    label_pred = pred2label(y_pred)\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(train_y_1d, label_pred)\n",
    "    prec = precision_score(train_y_1d,label_pred)\n",
    "\n",
    "    conf = confusion_matrix(train_y_1d, label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(train_y_1d, y_pred)\n",
    "    auc = roc_auc_score(train_y_1d, y_pred)\n",
    "\n",
    "    evaluations[\"Model\"].append(modelName)\n",
    "    evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "    evaluations[\"Dataset\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    print(\"Prediction and Evaluation on TRAIN dataset done for\",modelName,\"model.\")\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for EVAL dataset\n",
    "    ##################################################################################\n",
    "    \n",
    "    y_pred = model.predict(eval_X)\n",
    "    label_pred = pred2label(y_pred)\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(eval_y_1d, label_pred)\n",
    "    prec = precision_score(eval_y_1d,label_pred)\n",
    "\n",
    "    conf = confusion_matrix(eval_y_1d, label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(eval_y_1d, y_pred)\n",
    "    auc = roc_auc_score(eval_y_1d, y_pred)\n",
    "\n",
    "    evaluations[\"Model\"].append(modelName)\n",
    "    evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "    evaluations[\"Dataset\"].append(\"Eval\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    print(\"Prediction and Evaluation on EVAL dataset done for\",modelName,\"model.\")\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "    \n",
    "    y_pred = model.predict(test_X)\n",
    "    label_pred = pred2label(y_pred)\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(test_y_1d, label_pred)\n",
    "    prec = precision_score(test_y_1d,label_pred)\n",
    "\n",
    "    conf = confusion_matrix(test_y_1d, label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(test_y_1d, y_pred)\n",
    "    auc = roc_auc_score(test_y_1d, y_pred)\n",
    "\n",
    "    evaluations[\"Model\"].append(modelName)\n",
    "    evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "    evaluations[\"Dataset\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    print(\"Prediction and Evaluation on TEST dataset done for\",modelName,\"model.\")\n",
    "    \n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "##################################################################################\n",
    "##### Dump evaluations to a file\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "pickle.dump(evaluations,\n",
    "            open(os.path.join(evalPath, \"_Evaluation_All_Models_Datasets.pickle\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Parameters used only in this section\n",
    "##################################################################################\n",
    "\n",
    "expName = \"Test_Run_New_Dataset\"\n",
    "outPath = \"Generated\"\n",
    "\n",
    "modelNames = [\"DLNN_3\", \"DLNN_5\", \"DLNN_CORENup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"_Evaluation_All_Models_Datasets.pickle\"), \"rb\"))\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Kernel_Length</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DLNN_3</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.829875</td>\n",
       "      <td>0.875153</td>\n",
       "      <td>[0.0, 8.96780557797507e-05, 0.0172181867097121...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 9.078529278256922e-05, 9.07852...</td>\n",
       "      <td>[1.9990027, 0.99900275, 0.9822449, 0.9822313, ...</td>\n",
       "      <td>0.914581</td>\n",
       "      <td>0.793755</td>\n",
       "      <td>0.875153</td>\n",
       "      <td>0.664673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DLNN_3</td>\n",
       "      <td>3</td>\n",
       "      <td>Eval</td>\n",
       "      <td>0.813244</td>\n",
       "      <td>0.846764</td>\n",
       "      <td>[0.0, 0.000370919881305638, 0.0192878338278931...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00035137034434293746, 0.0003...</td>\n",
       "      <td>[1.998431, 0.9984309, 0.98204756, 0.98126894, ...</td>\n",
       "      <td>0.899368</td>\n",
       "      <td>0.787734</td>\n",
       "      <td>0.846764</td>\n",
       "      <td>0.628860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DLNN_3</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.818418</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>[0.0, 0.0002881014116969173, 0.017574186113511...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0002892681515765114, 0.00028...</td>\n",
       "      <td>[1.9980738, 0.9980738, 0.9850781, 0.98498976, ...</td>\n",
       "      <td>0.901970</td>\n",
       "      <td>0.789266</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>0.640070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DLNN_5</td>\n",
       "      <td>5</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.839258</td>\n",
       "      <td>0.868278</td>\n",
       "      <td>[0.0, 8.96780557797507e-05, 0.0071742444623800...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 9.078529278256922e-05, 9.07852...</td>\n",
       "      <td>[1.9991145, 0.9991146, 0.9937278, 0.993652, 0....</td>\n",
       "      <td>0.919098</td>\n",
       "      <td>0.814059</td>\n",
       "      <td>0.868278</td>\n",
       "      <td>0.680654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DLNN_5</td>\n",
       "      <td>5</td>\n",
       "      <td>Eval</td>\n",
       "      <td>0.816312</td>\n",
       "      <td>0.831621</td>\n",
       "      <td>[0.0, 0.000370919881305638, 0.0430267062314540...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00035137034434293746, 0.0003...</td>\n",
       "      <td>[1.9986666, 0.99866664, 0.9791268, 0.97895986,...</td>\n",
       "      <td>0.898650</td>\n",
       "      <td>0.803453</td>\n",
       "      <td>0.831621</td>\n",
       "      <td>0.632899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DLNN_5</td>\n",
       "      <td>5</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.825924</td>\n",
       "      <td>0.845380</td>\n",
       "      <td>[0.0, 0.0002881014116969173, 0.031403053874963...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0002892681515765114, 0.00028...</td>\n",
       "      <td>[1.9989741, 0.9989741, 0.9842477, 0.98417884, ...</td>\n",
       "      <td>0.902018</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.845380</td>\n",
       "      <td>0.652889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DLNN_CORENup</td>\n",
       "      <td>5,10</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.834070</td>\n",
       "      <td>0.899412</td>\n",
       "      <td>[0.0, 8.96780557797507e-05, 0.0064568200161420...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 9.078529278256922e-05, 9.07852...</td>\n",
       "      <td>[1.9987928, 0.99879277, 0.9876816, 0.98762393,...</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.786355</td>\n",
       "      <td>0.899412</td>\n",
       "      <td>0.677394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DLNN_CORENup</td>\n",
       "      <td>5,10</td>\n",
       "      <td>Eval</td>\n",
       "      <td>0.806748</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>[0.0, 0.000370919881305638, 0.0330118694362017...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00035137034434293746, 0.0003...</td>\n",
       "      <td>[1.9965618, 0.9965618, 0.97324014, 0.9731352, ...</td>\n",
       "      <td>0.901429</td>\n",
       "      <td>0.770497</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.619318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>DLNN_CORENup</td>\n",
       "      <td>5,10</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.814809</td>\n",
       "      <td>0.870596</td>\n",
       "      <td>[0.0, 0.0002881014116969173, 0.030250648228176...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0002892681515765114, 0.00028...</td>\n",
       "      <td>[1.9977965, 0.99779654, 0.9761234, 0.9760661, ...</td>\n",
       "      <td>0.903915</td>\n",
       "      <td>0.773390</td>\n",
       "      <td>0.870596</td>\n",
       "      <td>0.636915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Kernel_Length Dataset  Accuracy  Precision  \\\n",
       "0        DLNN_3             3   Train  0.829875   0.875153   \n",
       "1        DLNN_3             3    Eval  0.813244   0.846764   \n",
       "2        DLNN_3             3    Test  0.818418   0.853854   \n",
       "3        DLNN_5             5   Train  0.839258   0.868278   \n",
       "4        DLNN_5             5    Eval  0.816312   0.831621   \n",
       "5        DLNN_5             5    Test  0.825924   0.845380   \n",
       "6  DLNN_CORENup          5,10   Train  0.834070   0.899412   \n",
       "7  DLNN_CORENup          5,10    Eval  0.806748   0.859354   \n",
       "8  DLNN_CORENup          5,10    Test  0.814809   0.870596   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 8.96780557797507e-05, 0.0172181867097121...   \n",
       "1  [0.0, 0.000370919881305638, 0.0192878338278931...   \n",
       "2  [0.0, 0.0002881014116969173, 0.017574186113511...   \n",
       "3  [0.0, 8.96780557797507e-05, 0.0071742444623800...   \n",
       "4  [0.0, 0.000370919881305638, 0.0430267062314540...   \n",
       "5  [0.0, 0.0002881014116969173, 0.031403053874963...   \n",
       "6  [0.0, 8.96780557797507e-05, 0.0064568200161420...   \n",
       "7  [0.0, 0.000370919881305638, 0.0330118694362017...   \n",
       "8  [0.0, 0.0002881014116969173, 0.030250648228176...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0, 0.0, 9.078529278256922e-05, 9.07852...   \n",
       "1  [0.0, 0.0, 0.0, 0.00035137034434293746, 0.0003...   \n",
       "2  [0.0, 0.0, 0.0, 0.0002892681515765114, 0.00028...   \n",
       "3  [0.0, 0.0, 0.0, 9.078529278256922e-05, 9.07852...   \n",
       "4  [0.0, 0.0, 0.0, 0.00035137034434293746, 0.0003...   \n",
       "5  [0.0, 0.0, 0.0, 0.0002892681515765114, 0.00028...   \n",
       "6  [0.0, 0.0, 0.0, 9.078529278256922e-05, 9.07852...   \n",
       "7  [0.0, 0.0, 0.0, 0.00035137034434293746, 0.0003...   \n",
       "8  [0.0, 0.0, 0.0, 0.0002892681515765114, 0.00028...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9990027, 0.99900275, 0.9822449, 0.9822313, ...  0.914581     0.793755   \n",
       "1  [1.998431, 0.9984309, 0.98204756, 0.98126894, ...  0.899368     0.787734   \n",
       "2  [1.9980738, 0.9980738, 0.9850781, 0.98498976, ...  0.901970     0.789266   \n",
       "3  [1.9991145, 0.9991146, 0.9937278, 0.993652, 0....  0.919098     0.814059   \n",
       "4  [1.9986666, 0.99866664, 0.9791268, 0.97895986,...  0.898650     0.803453   \n",
       "5  [1.9989741, 0.9989741, 0.9842477, 0.98417884, ...  0.902018     0.808441   \n",
       "6  [1.9987928, 0.99879277, 0.9876816, 0.98762393,...  0.924370     0.786355   \n",
       "7  [1.9965618, 0.9965618, 0.97324014, 0.9731352, ...  0.901429     0.770497   \n",
       "8  [1.9977965, 0.99779654, 0.9761234, 0.9760661, ...  0.903915     0.773390   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.875153  0.664673  \n",
       "1     0.846764  0.628860  \n",
       "2     0.853854  0.640070  \n",
       "3     0.868278  0.680654  \n",
       "4     0.831621  0.632899  \n",
       "5     0.845380  0.652889  \n",
       "6     0.899412  0.677394  \n",
       "7     0.859354  0.619318  \n",
       "8     0.870596  0.636915  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Model\", \n",
    "                                                 \"Dataset\"]).mean().filter(['Accuracy',\n",
    "                                                                          'Precision', \n",
    "                                                                          'AUC', \n",
    "                                                                          'Sensitivity', \n",
    "                                                                          'Specificity', \n",
    "                                                                          'MCC'])\n",
    "\n",
    "DLNN_3_DF = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), ['DLNN_3'])]\n",
    "DLNN_5_DF = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), ['DLNN_5'])]\n",
    "DLNN_CORENup_DF = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), ['DLNN_CORENup'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">DLNN_CORENup</td>\n",
       "      <td>Eval</td>\n",
       "      <td>0.806748</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.901429</td>\n",
       "      <td>0.770497</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.619318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Test</td>\n",
       "      <td>0.814809</td>\n",
       "      <td>0.870596</td>\n",
       "      <td>0.903915</td>\n",
       "      <td>0.773390</td>\n",
       "      <td>0.870596</td>\n",
       "      <td>0.636915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.834070</td>\n",
       "      <td>0.899412</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.786355</td>\n",
       "      <td>0.899412</td>\n",
       "      <td>0.677394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy  Precision       AUC  Sensitivity  Specificity  \\\n",
       "Model        Dataset                                                            \n",
       "DLNN_CORENup Eval     0.806748   0.859354  0.901429     0.770497     0.859354   \n",
       "             Test     0.814809   0.870596  0.903915     0.773390     0.870596   \n",
       "             Train    0.834070   0.899412  0.924370     0.786355     0.899412   \n",
       "\n",
       "                           MCC  \n",
       "Model        Dataset            \n",
       "DLNN_CORENup Eval     0.619318  \n",
       "             Test     0.636915  \n",
       "             Train    0.677394  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DLNN_CORENup_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Eval', 'Test', 'Train'], dtype='object', name='Dataset')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DLNN_CORENup_DF.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Visualize with a multiple Bar chart\n",
    "##################################################################################\n",
    "\n",
    "x = np.arange(len(DLNN_CORENup_DF[metric_to_plot]))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,6))\n",
    "rects1 = ax.bar(x - (2.5*(width/2)), round(DLNN_3_DF[metric_to_plot]*100, 3), width, label='DLNN_3')\n",
    "rects2 = ax.bar(x + (0*(width/2)), round(DLNN_5_DF[metric_to_plot]*100, 3), width, label='DLNN_5')\n",
    "rects3 = ax.bar(x + (2.5*(width/2)), round(DLNN_CORENup_DF[metric_to_plot]*100, 3), width, label='DLNN_CORENup')\n",
    "\n",
    "## Custom y-axis tick labels\n",
    "ax.set_ylabel(metric_to_plot)\n",
    "ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "            (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "# ax.set_ylim([80, 105])\n",
    "\n",
    "## Custom x-axis tick labels\n",
    "ax.set_xticks(x)\n",
    "# ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "# ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "#                         zip(DLNN_CORENup_Train.index.get_level_values(0),DLNN_CORENup_Train.index.get_level_values(1))],\n",
    "#                   rotation=30)\n",
    "ax.set_xticklabels(DLNN_CORENup_DF.index.get_level_values(1),\n",
    "                  rotation=30)\n",
    "\n",
    "\n",
    "ax.set_title(metric_to_plot+' by Dataset and Model')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\", \n",
    "                    ha='center', va='bottom', rotation=90)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Iteratively generate comparison plot using every metric\n",
    "##################################################################################\n",
    "\n",
    "for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "    x = np.arange(len(DLNN_CORENup_DF[metric_to_plot]))\n",
    "    width = 0.15\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(17,6))\n",
    "    rects1 = ax.bar(x - (2.5*(width/2)), round(DLNN_3_DF[metric_to_plot]*100, 3), width, label='DLNN_3')\n",
    "    rects2 = ax.bar(x + (0*(width/2)), round(DLNN_5_DF[metric_to_plot]*100, 3), width, label='DLNN_5')\n",
    "    rects3 = ax.bar(x + (2.5*(width/2)), round(DLNN_CORENup_DF[metric_to_plot]*100, 3), width, label='DLNN_CORENup')\n",
    "\n",
    "    ## Custom y-axis tick labels\n",
    "    ax.set_ylabel(metric_to_plot)\n",
    "    ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "                (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "    # ax.set_ylim([80, 105])\n",
    "\n",
    "    ## Custom x-axis tick labels\n",
    "    ax.set_xticks(x)\n",
    "    # ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "    # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "    #                         zip(DLNN_CORENup_Train.index.get_level_values(0),DLNN_CORENup_Train.index.get_level_values(1))],\n",
    "    #                   rotation=30)\n",
    "    ax.set_xticklabels(DLNN_CORENup_DF.index.get_level_values(1),\n",
    "                      rotation=30)\n",
    "\n",
    "\n",
    "    ax.set_title(metric_to_plot+' by Dataset and Model')\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\", \n",
    "                        ha='center', va='bottom', rotation=90)\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    \n",
    "    plt.savefig(os.path.join(evalPath, \"{}_Comparison\".format(metric_to_plot)))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
