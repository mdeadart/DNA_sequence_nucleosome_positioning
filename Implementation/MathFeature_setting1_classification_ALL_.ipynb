{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# import xgboost as xgb\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "import math\n",
    "\n",
    "from lncRNAmiRNA import DForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all experiment parameters\n",
    "##################################################################################\n",
    "\n",
    "expName = \"MathFeature_setting1\"\n",
    "outPath = \"Generated\"\n",
    "\n",
    "dataset_path = \"Datasets\"\n",
    "setting = \"Setting1\"\n",
    "output_path = \"Results\"\n",
    "\n",
    "datafile_extensions = \".csv\"\n",
    "\n",
    "modelNames = [\"RandomForest\"]\n",
    "\n",
    "shuffle = False\n",
    "seed = None\n",
    "\n",
    "reject_encoding_list = [\"ALL\", \"NM-complex\", \"kmer\", \"kstep\", \"rckmer\"]\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "kernel_length = 5\n",
    "\n",
    "##################################################################################\n",
    "##### Define the modelling hyperparameters\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Checking the directory\n",
    "##################################################################################\n",
    "\n",
    "dataset_setting_path = os.path.join(outPath, expName, dataset_path, setting)\n",
    "dataset_varieties = next(os.walk(dataset_setting_path))\n",
    "result_output_path = os.path.join(outPath, expName, output_path, setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation by joining from all encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_variety in dataset_varieties[1]:\n",
    "    current_dataset_variety_path = os.path.join(dataset_setting_path, dataset_variety)\n",
    "    \n",
    "    \n",
    "    print(\"\\nProcessing variety: \", dataset_variety)\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(current_dataset_variety_path):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[-1] == datafile_extensions:\n",
    "                \n",
    "                encoding_type = file.split(\".\")[0].split(\"_\")[-1]\n",
    "                \n",
    "                if encoding_type not in reject_encoding_list:\n",
    "                \n",
    "                    input_file_full_path = os.path.join(root, file)\n",
    "\n",
    "                    ## check if input file has header\n",
    "                    file_obj = open(input_file_full_path, \"r\")\n",
    "                    first_line = file_obj.readline()\n",
    "                    file_obj.close()\n",
    "                    file_has_header = None\n",
    "                    if first_line.split(\",\")[0] == \"nameseq\" or first_line.replace(\"\\n\", \"\").split(\",\")[-1] == \"label\":\n",
    "                        file_has_header = 0\n",
    "\n",
    "                    sequences_df = pd.read_csv(input_file_full_path, header = file_has_header)\n",
    "                    \n",
    "                    # sequences_df = pd.read_csv(input_file_full_path, header = \"infer\")\n",
    "                    # print(\"Encoding completed adding: \", encoding_type)\n",
    "                    # print(\"Columns: \", sequences_df.columns)\n",
    "                    \n",
    "                    sequences_df = sequences_df.rename(columns = {sequences_df.columns[0] : 'nameseq', \n",
    "                                                                  sequences_df.columns[-1] : 'label'})\n",
    "                    \n",
    "                    sequences_df = sequences_df.drop(\"label\", axis = 1)\n",
    "                    \n",
    "                    if i == 0:\n",
    "                        variety_dataset_df = sequences_df\n",
    "                        \n",
    "                    else:\n",
    "                        # variety_dataset_df = pd.concat([variety_dataset_df, sequences_df], \n",
    "                        #                                join=\"inner\", \n",
    "                        #                                keys = (\"nameseq\"), \n",
    "                        #                                ignore_index = True, \n",
    "                        #                                axis = 1)\n",
    "                        # variety_dataset_df = variety_dataset_df.rename(columns = {0 : 'nameseq'})\n",
    "                        \n",
    "                        variety_dataset_df = pd.merge(variety_dataset_df, sequences_df, \n",
    "                                                      left_on='nameseq', right_on='nameseq', \n",
    "                                                      how='inner')\n",
    "                    \n",
    "                    print(\"Encoding completed adding: \", encoding_type)\n",
    "                    \n",
    "                    i = i+1\n",
    "                    \n",
    "    file_name = \"_\".join(file.split(\".\")[0].split(\"_\")[0:-1]+[\"ALL\"])+\".\"+file.split(\".\")[1]\n",
    "    variety_dataset_df.to_csv(os.path.join(root, file_name), \n",
    "                              header = True, \n",
    "                              index = False)\n",
    "    \n",
    "    print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "error_list = []\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Encoding_Type\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_setting_path):\n",
    "    for file in files:\n",
    "        if (os.path.splitext(file)[-1] == datafile_extensions) & (file.split(\".\")[0].split(\"_\")[-1] == \"ALL\"):\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "                encoding_type = file.split(\".\")[0].split(\"_\")[-1]\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### read the current file\n",
    "                ##################################################################################\n",
    "\n",
    "                input_file_full_path = os.path.join(root, file)\n",
    "                sequences_df = pd.read_csv(input_file_full_path, header = \"infer\", low_memory=False)\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### extract data from the current dataframe file\n",
    "                ##################################################################################\n",
    "\n",
    "                sequences_df[\"class\"] = np.where(sequences_df[sequences_df.columns[0]].str.contains(\"nucleosomal\"), 1, 0)\n",
    "\n",
    "                print(\"\\n======================================================================\")\n",
    "                print(\"\\nFile: \"+os.path.join(root, file))\n",
    "                print(\"Nucleosomi: \"+str(sum(sequences_df[\"class\"])))\n",
    "                print(\"Linker: \"+str(len(sequences_df) - sum(sequences_df[\"class\"])))\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### Generate Folds from dataset, and store to file\n",
    "                ##################################################################################\n",
    "\n",
    "                ## create the features and labels datasets for the training\n",
    "                labels = np.array(sequences_df[\"class\"])\n",
    "                # print(\"label extracted\")\n",
    "                features = sequences_df.drop(\"nameseq\", axis = 1).drop(\"class\", axis = 1).values\n",
    "                # print(\"features extracted\")\n",
    "                features = features.astype(np.float32)\n",
    "                # print(\"features type casted\")\n",
    "                features = features.reshape(features.shape + (1,))\n",
    "                \n",
    "                # input_size = (features.shape[1], features.shape[2])\n",
    "                \n",
    "                ## Parameters to Read/Write the k-fold dataset to file\n",
    "                foldPath = os.path.join(result_output_path, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "                foldName = file.split(\".\")[0]+\"_{}fold\".format(n_fold)+\".pickle\"\n",
    "\n",
    "                ##### ADDITIONAL CHANGES - USE PREVIOUS GENERATED FOLDS IF AVAILABLE\n",
    "\n",
    "                if(os.path.isfile(os.path.join(foldPath, foldName))):\n",
    "                    folds = pickle.load(open(os.path.join(foldPath, foldName), \"rb\"))\n",
    "                else:\n",
    "                    ## Generate the k-fold dataset\n",
    "                    folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "                    if(not os.path.isdir(foldPath)):\n",
    "                        os.makedirs(foldPath)\n",
    "                    pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "                    \n",
    "                print(\"MODEL!\")    \n",
    "                \n",
    "                for modelName in modelNames:\n",
    "\n",
    "                    ## Create and set directory to save model\n",
    "                    modelPath = os.path.join(result_output_path, current_dataset_variety, \"{}fold\".format(n_fold), \"models\", modelName)\n",
    "                    if(not os.path.isdir(modelPath)):\n",
    "                        os.makedirs(modelPath)\n",
    "\n",
    "                    ## fold counter\n",
    "                    i = 0\n",
    "\n",
    "                    for fold in folds:\n",
    "\n",
    "                        print(\"\\nTrain/Test model \"+modelName+\" on Fold #\"+str(i)+\".\")\n",
    "\n",
    "                        ## Generate model using function\n",
    "                        # model = RandomForestClassifier(n_estimators=50, \n",
    "                        #                                criterion='entropy', \n",
    "                        #                                bootstrap=True,\n",
    "                        #                                oob_score=True, \n",
    "                        #                                warm_start = True)\n",
    "                        \n",
    "                        # model = ExtraTreesClassifier(n_estimators=50, \n",
    "                        #                              criterion='gini', \n",
    "                        #                              bootstrap=True,\n",
    "                        #                              oob_score=True, \n",
    "                        #                              warm_start = True)\n",
    "                        \n",
    "                        # model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "                        \n",
    "                        # model = SVC(C = 2,\n",
    "                        #             kernel = \"rbf\",\n",
    "                        #             # degree = 5, # only for kernel = poly\n",
    "                        #             gamma = \"scale\", # only for kernel = rbf/poly/sigmoid\n",
    "                        #             max_iter = -1)\n",
    "                        \n",
    "                        # model.fit(X = fold[\"X_train\"], y = fold[\"y_train\"])\n",
    "                        \n",
    "                        # model_filename = \"{}_fold{}_model.pickle\".format(encoding_type, i)\n",
    "                        \n",
    "                        # model_file_obj = open(os.path.join(modelPath, model_filename), 'wb')\n",
    "                        # pickle.dump(model, model_file_obj)\n",
    "                        # model_file_obj.close()\n",
    "                        \n",
    "                        ## Generate model using function\n",
    "                        # model = Conv_LSTM_DLNN(input_shape = input_size, \n",
    "                        #                        conv_filters_per_layer = 50, kernel_length = kernel_length, \n",
    "                        #                        lstm_decode_units = 50,\n",
    "                        #                        prob = 0.5, \n",
    "                        #                        learn_rate = 0.001, loss = 'binary_crossentropy', metrics = None, \n",
    "                        #                        max_pool_width = 2, max_pool_stride = 2, \n",
    "                        #                        dense_decode_units = 150)\n",
    "                        \n",
    "                        input_size = (fold[\"X_train\"].shape[1],)\n",
    "                        \n",
    "                        ## Generate model using function\n",
    "                        model = FCNN(input_shape=input_size, \n",
    "                                     dense_decode_units_1 = input_size[0],\n",
    "                                     dense_decode_units_2 = 150,\n",
    "                                     max_pool_stride = 2, max_pool_width = 2,\n",
    "                                     learn_rate = 0.001, prob = 0.5, loss = 'binary_crossentropy', metrics = None)\n",
    "                        \n",
    "                        ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "                        modelCallbacks = [\n",
    "                            tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(modelName, i)),\n",
    "                                                               monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "                                                               save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "                            tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, \n",
    "                                                             mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "                        ]\n",
    "                        model.fit(x = fold[\"X_train\"].reshape(fold[\"X_train\"].shape[0], fold[\"X_train\"].shape[1]), \n",
    "                                  y = fold[\"y_train\"], batch_size = batch_size, epochs = epochs, verbose = 0, \n",
    "                                  callbacks = modelCallbacks, validation_data = (fold[\"X_test\"].reshape(fold[\"X_test\"].shape[0], fold[\"X_test\"].shape[1]), \n",
    "                                                                                 fold[\"y_test\"]))\n",
    "\n",
    "                        ##################################################################################\n",
    "                        ##### Prediction and metrics for TRAIN dataset\n",
    "                        ##################################################################################\n",
    "\n",
    "                        y_pred = model.predict(fold[\"X_train\"].reshape(fold[\"X_train\"].shape[0], fold[\"X_train\"].shape[1]))\n",
    "                        label_pred = pred2label(y_pred)\n",
    "                        # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                        acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "                        prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "                        conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "                        if(conf[0][0]+conf[1][0]):\n",
    "                            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                        else:\n",
    "                            sens = 0.0\n",
    "                        if(conf[1][1]+conf[0][1]):\n",
    "                            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                        else:\n",
    "                            spec = 0.0\n",
    "                        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                        else:\n",
    "                            mcc= 0.0\n",
    "                        fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "                        auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "                        evaluations[\"Model\"].append(modelName)\n",
    "                        evaluations[\"Encoding_Type\"].append(encoding_type)\n",
    "                        evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                        evaluations[\"Fold\"].append(i)\n",
    "                        evaluations[\"Train_Test\"].append(\"Train\")\n",
    "                        evaluations[\"Accuracy\"].append(acc)\n",
    "                        evaluations[\"Precision\"].append(prec)\n",
    "                        evaluations[\"TPR\"].append(tpr)\n",
    "                        evaluations[\"FPR\"].append(fpr)\n",
    "                        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                        evaluations[\"AUC\"].append(auc)\n",
    "                        evaluations[\"Sensitivity\"].append(sens)\n",
    "                        evaluations[\"Specificity\"].append(spec)\n",
    "                        evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "                        ##################################################################################\n",
    "                        ##### Prediction and metrics for TEST dataset\n",
    "                        ##################################################################################\n",
    "\n",
    "                        y_pred = model.predict(fold[\"X_test\"].reshape(fold[\"X_test\"].shape[0], fold[\"X_test\"].shape[1]))\n",
    "                        label_pred = pred2label(y_pred)\n",
    "                        # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                        acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "                        prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "                        conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "                        if(conf[0][0]+conf[1][0]):\n",
    "                            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                        else:\n",
    "                            sens = 0.0\n",
    "                        if(conf[1][1]+conf[0][1]):\n",
    "                            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                        else:\n",
    "                            spec = 0.0\n",
    "                        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                        else:\n",
    "                            mcc= 0.0\n",
    "                        fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "                        auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "                        evaluations[\"Model\"].append(modelName)\n",
    "                        evaluations[\"Encoding_Type\"].append(encoding_type)\n",
    "                        evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                        evaluations[\"Fold\"].append(i)\n",
    "                        evaluations[\"Train_Test\"].append(\"Test\")\n",
    "                        evaluations[\"Accuracy\"].append(acc)\n",
    "                        evaluations[\"Precision\"].append(prec)\n",
    "                        evaluations[\"TPR\"].append(tpr)\n",
    "                        evaluations[\"FPR\"].append(fpr)\n",
    "                        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                        evaluations[\"AUC\"].append(auc)\n",
    "                        evaluations[\"Sensitivity\"].append(sens)\n",
    "                        evaluations[\"Specificity\"].append(spec)\n",
    "                        evaluations[\"MCC\"].append(mcc)\n",
    "                        \n",
    "                        i = i+1\n",
    "                        \n",
    "            except Exception as error:\n",
    "                error_list.append((input_file_full_path, error))\n",
    "                \n",
    "##################################################################################\n",
    "##### Dump evaluations to a file\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(result_output_path, \"_Evaluation_All_Datasets\", \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "pickle.dump(evaluations,\n",
    "            open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelNames[0])), \"wb\"))\n",
    "\n",
    "##################################################################################\n",
    "##### Dump exceptions to a file\n",
    "##################################################################################\n",
    "\n",
    "pickle.dump(error_list,\n",
    "            open(os.path.join(result_output_path, \"exceptions.pickle\"), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Parameters used only in this section\n",
    "# ##################################################################################\n",
    "\n",
    "# n_fold = 10\n",
    "\n",
    "# expName = \"MathFeature_setting1_kgap_fickett\"\n",
    "# outPath = \"Generated\"\n",
    "# setting = \"Setting1\"\n",
    "# output_path = \"Results\"\n",
    "\n",
    "# modelNames = [\"RandomForest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, output_path, setting, \"_Evaluation_All_Datasets\", \"{}fold\".format(n_fold))\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, modelNames[0])), \"rb\"))\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Encoding_Type</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ANF</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ANF</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.657391</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>[0.0, 0.4689655172413793, 1.0]</td>\n",
       "      <td>[0.0, 0.15087719298245614, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.659044</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.343475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ANF</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ANF</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.688696</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>[0.0, 0.5379310344827586, 1.0]</td>\n",
       "      <td>[0.0, 0.15789473684210525, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.690018</td>\n",
       "      <td>0.641711</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.398486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ANF</td>\n",
       "      <td>Drosophila</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2535</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TNC</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>7</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.997238</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.005747126436781609, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.997126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.994481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2536</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TNC</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>8</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2537</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TNC</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>8</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.997238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.9946808510638298, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2538</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TNC</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>9</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2539</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TNC</td>\n",
       "      <td>Yeast</td>\n",
       "      <td>9</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.997230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.9946524064171123, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2540 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model Encoding_Type     Dataset  Fold Train_Test  Accuracy  \\\n",
       "0     RandomForest           ANF  Drosophila     0      Train  1.000000   \n",
       "1     RandomForest           ANF  Drosophila     0       Test  0.657391   \n",
       "2     RandomForest           ANF  Drosophila     1      Train  1.000000   \n",
       "3     RandomForest           ANF  Drosophila     1       Test  0.688696   \n",
       "4     RandomForest           ANF  Drosophila     2      Train  1.000000   \n",
       "...            ...           ...         ...   ...        ...       ...   \n",
       "2535  RandomForest           TNC       Yeast     7       Test  0.997238   \n",
       "2536  RandomForest           TNC       Yeast     8      Train  1.000000   \n",
       "2537  RandomForest           TNC       Yeast     8       Test  0.997238   \n",
       "2538  RandomForest           TNC       Yeast     9      Train  1.000000   \n",
       "2539  RandomForest           TNC       Yeast     9       Test  0.997230   \n",
       "\n",
       "      Precision                             TPR  \\\n",
       "0      1.000000                 [0.0, 1.0, 1.0]   \n",
       "1      0.759777  [0.0, 0.4689655172413793, 1.0]   \n",
       "2      1.000000                 [0.0, 1.0, 1.0]   \n",
       "3      0.776119  [0.0, 0.5379310344827586, 1.0]   \n",
       "4      1.000000                 [0.0, 1.0, 1.0]   \n",
       "...         ...                             ...   \n",
       "2535   0.994709                 [0.0, 1.0, 1.0]   \n",
       "2536   1.000000                 [0.0, 1.0, 1.0]   \n",
       "2537   1.000000  [0.0, 0.9946808510638298, 1.0]   \n",
       "2538   1.000000                 [0.0, 1.0, 1.0]   \n",
       "2539   1.000000  [0.0, 0.9946524064171123, 1.0]   \n",
       "\n",
       "                                   FPR TPR_FPR_Thresholds       AUC  \\\n",
       "0                      [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "1      [0.0, 0.15087719298245614, 1.0]          [2, 1, 0]  0.659044   \n",
       "2                      [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "3      [0.0, 0.15789473684210525, 1.0]          [2, 1, 0]  0.690018   \n",
       "4                      [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "...                                ...                ...       ...   \n",
       "2535  [0.0, 0.005747126436781609, 1.0]          [2, 1, 0]  0.997126   \n",
       "2536                   [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "2537                   [0.0, 0.0, 1.0]          [2, 1, 0]  0.997340   \n",
       "2538                   [0.0, 0.0, 1.0]          [2, 1, 0]  1.000000   \n",
       "2539                   [0.0, 0.0, 1.0]          [2, 1, 0]  0.997326   \n",
       "\n",
       "      Sensitivity  Specificity       MCC  \n",
       "0        1.000000     1.000000  1.000000  \n",
       "1        0.611111     0.759777  0.343475  \n",
       "2        1.000000     1.000000  1.000000  \n",
       "3        0.641711     0.776119  0.398486  \n",
       "4        1.000000     1.000000  1.000000  \n",
       "...           ...          ...       ...  \n",
       "2535     1.000000     0.994709  0.994481  \n",
       "2536     1.000000     1.000000  1.000000  \n",
       "2537     0.994286     1.000000  0.994483  \n",
       "2538     1.000000     1.000000  1.000000  \n",
       "2539     0.994286     1.000000  0.994469  \n",
       "\n",
       "[2540 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Dataset\",\n",
    "                                                 \"Encoding_Type\",\n",
    "                                                 \"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "# Eval_Train = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(3), ['Train'])]\n",
    "# Eval_Test = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(3), ['Test'])]\n",
    "\n",
    "# datasets = np.unique(evaluations_df_grouped.index.get_level_values(0))\n",
    "\n",
    "# evaluations_df_grouped = evaluations_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Available :  ['Accuracy', 'Precision', 'AUC', 'Sensitivity', 'Specificity', 'MCC']\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Decide on metric to visualize\n",
    "##################################################################################\n",
    "\n",
    "print(\"Metrics Available : \", list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Visualize with a multiple Bar chart\n",
    "##################################################################################\n",
    "\n",
    "# df = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), [dataset_to_print])]\n",
    "# df = evaluations_df_grouped.reset_index(level=['Dataset', 'Encoding_Type', 'Train_Test'])\n",
    "df = evaluations_df_grouped.reset_index()\n",
    "\n",
    "# Some boilerplate to initialise things\n",
    "sns.set()\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "# Draw the bars\n",
    "ax = sns.barplot(data=df, x=\"Dataset\", y=metric_to_plot, hue=\"Train_Test\")\n",
    "\n",
    "# Customise some display properties\n",
    "ax.set_title(metric_to_plot)\n",
    "ax.grid(color='#cccccc')\n",
    "ax.set_ylabel(metric_to_plot)\n",
    "ax.set_xlabel(\"Dataset\")\n",
    "ax.set_xticklabels(df[\"Dataset\"].unique().astype(str), rotation='vertical')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height()*100, '.4f'),\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                size=15,\n",
    "                xytext = (0, -12), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "##############################\n",
    "\n",
    "# Ask Matplotlib to show it\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Iteratively generate comparison plot using every metric\n",
    "##################################################################################\n",
    "\n",
    "for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    for dataset_to_print in datasets:\n",
    "    \n",
    "        # df = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(0), [dataset_to_print])]\n",
    "        # df = evaluations_df_grouped.reset_index(level=['Dataset', 'Encoding_Type', 'Train_Test'])\n",
    "        df = evaluations_df_grouped.reset_index()\n",
    "\n",
    "        # Some boilerplate to initialise things\n",
    "        sns.set()\n",
    "        plt.figure(figsize=(20,8))\n",
    "\n",
    "        # Draw the bars\n",
    "        ax = sns.barplot(data=df, x=\"Dataset\", y=metric_to_plot, hue=\"Train_Test\")\n",
    "\n",
    "        # Customise some display properties\n",
    "        ax.set_title(dataset_to_print)\n",
    "        ax.grid(color='#cccccc')\n",
    "        ax.set_ylabel(metric_to_plot)\n",
    "        ax.set_xlabel(\"Dataset\")\n",
    "        ax.set_xticklabels(df[\"Dataset\"].unique().astype(str), rotation='vertical')\n",
    "\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(format(p.get_height()*100, '.4f'),\n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha = 'center', va = 'center', \n",
    "                        size=15,\n",
    "                        xytext = (0, -12), \n",
    "                        textcoords = 'offset points')\n",
    "        \n",
    "        plt.savefig(os.path.join(evalPath, \"{}_{}_{}_Comparison\".format(metric_to_plot, dataset_to_print, modelNames[0])))\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
