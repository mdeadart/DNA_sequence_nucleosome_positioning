{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import math\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "from DNA_Encoding import DNA_Encoding\n",
    "import r2v_functions_mod as r2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 10\n",
    "expName = \"allModels_piRNA_generate\"\n",
    "outPath = \"Generated\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "kmer_word2vec = 6\n",
    "\n",
    "modelNames = [\"DLNN_3\", \"DLNN_5\", \"DLNN_CORENup\", \"Dense_{}mer_word2vec\".format(kmer_word2vec), \"GlobalEmbed_RandomForest\"]\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "shuffle = False\n",
    "seed = 42\n",
    "\n",
    "dataset_path = \"piRNA\"\n",
    "dataset_filename = \"piRNA_layer1.csv\"\n",
    "\n",
    "obj_DNA_Encoding = DNA_Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define custom one hot encoding, contains code from repository\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),4))\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"T\":3\n",
    "    }\n",
    "    i = 0\n",
    "    \n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in dict_nuc.keys()):\n",
    "            seq_encoded[i][dict_nuc[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    return seq_encoded\n",
    "\n",
    "def padded_one_hot_encode(sequence, max_len):\n",
    "    \n",
    "    cur_seq_len = len(sequence)\n",
    "    ohe_seq = one_hot_encode(sequence)\n",
    "    \n",
    "    if cur_seq_len<max_len:\n",
    "        add_seq_inst_count = max_len - cur_seq_len\n",
    "        ohe_seq = np.concatenate((ohe_seq, np.zeros((add_seq_inst_count, ohe_seq.shape[1]))))\n",
    "    \n",
    "    return ohe_seq\n",
    "\n",
    "def generator_of_sequences(seq_list, id_list):\n",
    "        id_n = 0\n",
    "        id_l = 0\n",
    "        for string_seq, id_01 in zip(seq_list, id_list):\n",
    "            if id_01 == 0:\n",
    "                id_l = id_l + 1\n",
    "                push_id = \"linker_sequence_{}\".format(id_l)\n",
    "            elif id_01 == 1:\n",
    "                id_n = id_n + 1\n",
    "                push_id = \"nucleosomal_sequence_{}\".format(id_n)\n",
    "            yield SeqRecord(Seq(string_seq), id=push_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to generate the NN with dense FC layers only\n",
    "##################################################################################\n",
    "\n",
    "def DenseNN(input_shape=(64), learn_rate = 0.0003, loss = 'binary_crossentropy', metrics = None, \n",
    "            dense_decode_units = 64, beta = 0.001):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.Input(shape = input_shape))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(dense_decode_units, activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss, metrics = metrics) \n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN network architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def Conv_LSTM_DLNN(input_shape=(150,4), conv_filters_per_layer = 50, kernel_length = 5, lstm_decode_units = 50, \n",
    "                   learn_rate = 0.0003, prob = 0.5, loss = 'binary_crossentropy', metrics = None, max_pool_width = 2, \n",
    "                   max_pool_stride = 2, dense_decode_units = 150):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv1D(conv_filters_per_layer, kernel_length, input_shape = input_shape, \n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(beta), padding=\"same\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.MaxPool1D(pool_size = max_pool_width, strides = max_pool_stride))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2(beta), dropout = 0.1))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras .layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(dense_decode_units, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(prob))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(beta), activation='sigmoid'))\n",
    "    \n",
    "    #[tf.keras.metrics.binary_accuracy, metrics.precision, metrics.recall, metrics.f1score])\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss, metrics = metrics) \n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN CORENup network architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_shape = (150,4),\n",
    "                 conv_filters_per_layer_1 = 50, kernel_length_1 = 5, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 2, max_pool_stride_1 = 2, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 50, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 50,  kernel_length_2 = 10, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 2, max_pool_stride_2 = 2, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 370, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0003, loss = 'binary_crossentropy', metrics = None, beta = 0.001):\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1, input_shape = input_shape, \n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              dropout=0.1)(x1)\n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "\n",
    "    ## Fully connected Layers\n",
    "\n",
    "    y = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    y1 = tf.keras.layers.Dense(dense_decode_units, kernel_regularizer = tf.keras.regularizers.l2(beta), activation = 'relu')(y)\n",
    "    \n",
    "    y1 = tf.keras.layers.Dropout(prob)(y1)\n",
    "    \n",
    "    y1 = tf.keras.layers.Dense(1, kernel_regularizer = tf.keras.regularizers.l2(beta), activation = 'sigmoid')(y1)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=[input1], outputs=y1)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to generate the NN with dense FC layers only\n",
    "##################################################################################\n",
    "\n",
    "def DenseNN(input_shape=(64), learn_rate = 0.0003, loss = 'binary_crossentropy', metrics = None, \n",
    "            dense_decode_units = 64):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.Input(shape = input_shape))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(dense_decode_units, activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss, metrics = metrics) \n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr = learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate metric outputs\n",
    "##################################################################################\n",
    "\n",
    "org_ACGU_data_list = []\n",
    "org_ACGT_data_list = []\n",
    "zero_padded_ohe_ACGT_data_list = []\n",
    "max_len = 0\n",
    "\n",
    "##################################################################################\n",
    "##### read the current file\n",
    "##################################################################################\n",
    "\n",
    "with open(os.path.join(dataset_path, dataset_filename), newline='\\n') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        if len(row[0]) > max_len:\n",
    "            max_len = len(row[0])\n",
    "        org_ACGU_data_list.append(row)\n",
    "\n",
    "##################################################################################\n",
    "##### pre process data as required by the models\n",
    "##################################################################################\n",
    "\n",
    "## converting U to T and removing all numeric characters\n",
    "for row in org_ACGU_data_list: \n",
    "    org_ACGT_data_list.append([''.join([i for i in row[0].replace(\"U\", \"T\") if not i.isdigit()]), row[1]])\n",
    "\n",
    "##################################################################################\n",
    "##### Generate Folds from dataset, and store to file\n",
    "##################################################################################\n",
    "\n",
    "labels = np.array([int(row[1]) for row in org_ACGT_data_list])\n",
    "features = np.array([row[0] for row in org_ACGT_data_list])\n",
    "\n",
    "## Generate the k-fold dataset\n",
    "folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "print(\"Max length:\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### TRAIN and PREDICT for every Fold, using both models (DLNN3 and DLNN5)\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "# fold counter\n",
    "i = 0\n",
    "\n",
    "## Working only with the ACGT data - folds were created after conversion to ACGT\n",
    "for fold in folds:\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Create training and testing datasets using padded one hot encoding\n",
    "    ##################################################################################\n",
    "    \n",
    "    fold_Xtrain_paddedOHE = np.array([padded_one_hot_encode(row, max_len) for row in fold[\"X_train\"]])\n",
    "    fold_Xtest_paddedOHE = np.array([padded_one_hot_encode(row, max_len) for row in fold[\"X_test\"]])\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Create training and testing datasets using Global DNA Encoding\n",
    "    ##################################################################################\n",
    "    \n",
    "    fold_Xtrain_paddedOHE_GlobalDNAenc = np.array([DNA_Encoding.GlobalEncoding(self = obj_DNA_Encoding, seq = row) \n",
    "                                                   for row in fold[\"X_train\"]])\n",
    "    fold_Xtest_paddedOHE_GlobalDNAenc = np.array([DNA_Encoding.GlobalEncoding(self = obj_DNA_Encoding, seq = row) \n",
    "                                                   for row in fold[\"X_test\"]])\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Create training and testing datasets using word2vec\n",
    "    ##################################################################################\n",
    "    \n",
    "    word2vec_model_extension = \"6_64_3_5_5_0.0001_10\"\n",
    "\n",
    "    path_reads_train = os.path.join(dataset_path, dataset_filename.split(\".\")[0]+\"_fold{}_train.fas\".format(i))\n",
    "    path_reads_test = os.path.join(dataset_path, dataset_filename.split(\".\")[0]+\"_fold{}_test.fas\".format(i))\n",
    "    path_model = os.path.join(dataset_path, dataset_filename.split(\".\")[0]+\"_\"+word2vec_model_extension+\"_model.pkl\")\n",
    "    path_totalkmers = os.path.join(dataset_path, dataset_filename.split(\".\")[0]+\"_{}_totalkmers.pkl\".format(kmer_word2vec))\n",
    "\n",
    "    id_List = fold[\"y_train\"]\n",
    "    seq_List = fold[\"X_train\"]\n",
    "    output_handle = open(path_reads_train, \"w\")\n",
    "    SeqIO.write(generator_of_sequences(seq_List, id_List), output_handle, \"fasta\")\n",
    "    output_handle.close()\n",
    "\n",
    "    id_List = fold[\"y_test\"]\n",
    "    seq_List = fold[\"X_test\"]\n",
    "    output_handle = open(path_reads_test, \"w\")\n",
    "    SeqIO.write(generator_of_sequences(seq_List, id_List), output_handle, \"fasta\")\n",
    "    output_handle.close()\n",
    "\n",
    "    nr = bool(int(1))\n",
    "    a = 1e-05\n",
    "    v = 1000\n",
    "    k = kmer_word2vec\n",
    "    r2v.embed_reads(path_sample = path_reads_train, path_totalkmers = path_totalkmers, path_model = path_model, path_out = dataset_path, normread=nr, k=k, a=a, verbose=True, v=v)\n",
    "    r2v.embed_reads(path_sample = path_reads_test, path_totalkmers = path_totalkmers, path_model = path_model, path_out = dataset_path, normread=nr, k=k, a=a, verbose=True, v=v)\n",
    "    \n",
    "    train_word2vec_reads = \"\".join(path_reads_train.split(\".\")[0:len(path_reads_train.split(\".\"))-1])+\"_\"+'_'.join(path_model.split('\\\\')[-1].split('_')[1:-1])+'_'+str(a)+\"_remb.csv.gz\"\n",
    "    test_word2vec_reads = \"\".join(path_reads_test.split(\".\")[0:len(path_reads_test.split(\".\"))-1])+\"_\"+'_'.join(path_model.split('\\\\')[-1].split('_')[1:-1])+'_'+str(a)+\"_remb.csv.gz\"\n",
    "    \n",
    "    fold_train_word2vec_df = pd.read_csv(train_word2vec_reads, compression='gzip', header=0)\n",
    "    fold_test_word2vec_df = pd.read_csv(test_word2vec_reads, compression='gzip', header=0)\n",
    "\n",
    "    fold_train_nucleosomal_feature_list = fold_train_word2vec_df[fold_train_word2vec_df['Unnamed: 0'].str.contains(\"nucleosomal\")].drop('Unnamed: 0',1).values.tolist()\n",
    "    fold_train_linker_feature_list = fold_train_word2vec_df[fold_train_word2vec_df['Unnamed: 0'].str.contains(\"linker\")].drop('Unnamed: 0',1).values.tolist()\n",
    "    fold_test_nucleosomal_feature_list = fold_test_word2vec_df[fold_test_word2vec_df['Unnamed: 0'].str.contains(\"nucleosomal\")].drop('Unnamed: 0',1).values.tolist()\n",
    "    fold_test_linker_feature_list = fold_test_word2vec_df[fold_test_word2vec_df['Unnamed: 0'].str.contains(\"linker\")].drop('Unnamed: 0',1).values.tolist()\n",
    "    \n",
    "    fold_train_word2vec_labels = np.concatenate((np.ones((len(fold_train_nucleosomal_feature_list), 1), dtype=np.float32), np.zeros((len(fold_train_linker_feature_list), 1), dtype=np.float32)), axis=0)\n",
    "    fold_train_word2vec_features = np.concatenate((fold_train_nucleosomal_feature_list, fold_train_linker_feature_list), 0)\n",
    "    fold_test_word2vec_labels = np.concatenate((np.ones((len(fold_test_nucleosomal_feature_list), 1), dtype=np.float32), np.zeros((len(fold_test_linker_feature_list), 1), dtype=np.float32)), axis=0)\n",
    "    fold_test_word2vec_features = np.concatenate((fold_test_nucleosomal_feature_list, fold_test_linker_feature_list), 0)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Train all different models using the \n",
    "    ##################################################################################\n",
    "    \n",
    "    for modelName in modelNames:\n",
    "        \n",
    "        modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\", modelName)\n",
    "        if(not os.path.isdir(modelPath)):\n",
    "            os.makedirs(modelPath)\n",
    "        \n",
    "        ##################################################################################\n",
    "        ##### DLNN convolution-LSTM network\n",
    "        ##################################################################################\n",
    "        \n",
    "        if modelName == \"DLNN_3\" or modelName == \"DLNN_5\":\n",
    "            train_features = fold_Xtrain_paddedOHE\n",
    "            test_features = fold_Xtest_paddedOHE\n",
    "            train_labels = fold[\"y_train\"]\n",
    "            test_labels = fold[\"y_test\"]\n",
    "            \n",
    "            kernel_length = int(modelName[-1])\n",
    "            \n",
    "            input_shape = fold_Xtrain_paddedOHE[0].shape\n",
    "            \n",
    "            ## Generate model using function\n",
    "            model = Conv_LSTM_DLNN(input_shape = input_shape, conv_filters_per_layer = 50, kernel_length = kernel_length,\n",
    "                                   lstm_decode_units = 50, learn_rate = 0.0003, prob = 0.5, loss='binary_crossentropy',\n",
    "                                   metrics=None)\n",
    "            \n",
    "            ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "            modelCallbacks = [\n",
    "                tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(modelName, i)),\n",
    "                                                   monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "                                                   save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "                tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, \n",
    "                                                 mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "            ]\n",
    "            model.fit(x = train_features, y = train_labels, batch_size = batch_size, epochs = epochs, \n",
    "                      callbacks = modelCallbacks, validation_data = (test_features, test_labels))\n",
    "        \n",
    "        ##################################################################################\n",
    "        ##### CORENup DLNN convolution-LSTM network\n",
    "        ##################################################################################\n",
    "        \n",
    "        elif modelName == \"DLNN_CORENup\":\n",
    "            train_features = fold_Xtrain_paddedOHE\n",
    "            test_features = fold_Xtest_paddedOHE\n",
    "            train_labels = fold[\"y_train\"]\n",
    "            test_labels = fold[\"y_test\"]\n",
    "            \n",
    "            input_shape = fold_Xtrain_paddedOHE[0].shape\n",
    "            \n",
    "            ## Generate model using function\n",
    "            model = DLNN_CORENup(input_shape = input_shape)\n",
    "            \n",
    "            ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "            modelCallbacks = [\n",
    "                tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(modelName, i)),\n",
    "                                                   monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "                                                   save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "                tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, \n",
    "                                                 mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "            ]\n",
    "            model.fit(x = train_features, y = train_labels, batch_size = batch_size, epochs = epochs, \n",
    "                      callbacks = modelCallbacks, validation_data = (test_features, test_labels))\n",
    "        \n",
    "        ##################################################################################\n",
    "        ##### word2vec embedding with A fully connected NN layer\n",
    "        ##################################################################################\n",
    "        \n",
    "        elif modelName == \"Dense_{}mer_word2vec\".format(kmer_word2vec):\n",
    "            train_features = fold_train_word2vec_features\n",
    "            test_features = fold_test_word2vec_features\n",
    "            train_labels = fold_train_word2vec_labels\n",
    "            test_labels = fold_test_word2vec_labels\n",
    "            \n",
    "            input_shape = (fold_test_word2vec_features[0].shape[0])\n",
    "            \n",
    "            ## Generate model using function\n",
    "            model = DenseNN(input_shape = input_shape)\n",
    "            \n",
    "            ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "            modelCallbacks = [\n",
    "                tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(modelName, i)),\n",
    "                                                   monitor = 'val_loss', verbose = 0, save_best_only = True, \n",
    "                                                   save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "                tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, \n",
    "                                                 mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "            ]\n",
    "            model.fit(x = train_features, y = train_labels, batch_size = batch_size, epochs = epochs, verbose = 0, \n",
    "                      callbacks = modelCallbacks, validation_data = (test_features, test_labels))\n",
    "        \n",
    "        ##################################################################################\n",
    "        ##### Global DNA Encoding with Random Forest\n",
    "        ##################################################################################\n",
    "            \n",
    "        elif modelName == \"GlobalEmbed_RandomForest\":\n",
    "            train_features = fold_Xtrain_paddedOHE_GlobalDNAenc\n",
    "            test_features = fold_Xtest_paddedOHE_GlobalDNAenc\n",
    "            train_labels = fold[\"y_train\"].reshape(fold[\"y_train\"].shape[0])\n",
    "            test_labels = fold[\"y_test\"].reshape(fold[\"y_test\"].shape[0])\n",
    "            \n",
    "            model = RandomForestClassifier(n_estimators = 100, random_state = 42, oob_score = True, criterion = \"gini\")\n",
    "\n",
    "            model.fit(X = fold_Xtrain_paddedOHE_GlobalDNAenc, \n",
    "                      y = fold[\"y_train\"].reshape(fold[\"y_train\"].shape[0]))\n",
    "            \n",
    "            pickle.dump(model, open(os.path.join(modelPath, \"{}_bestModel-fold{}.pkl\".format(modelName, i)), 'wb'))\n",
    "        \n",
    "        ##################################################################################\n",
    "        ##### Generate metrics on Train/test data per folds and add to Evaluations DF\n",
    "        ##################################################################################\n",
    "        \n",
    "        # train_features\n",
    "        # test_features\n",
    "        # train_labels\n",
    "        # test_labels\n",
    "        \n",
    "        ##################################################################################\n",
    "        ##### Prediction and metrics for TRAIN dataset\n",
    "        ##################################################################################\n",
    "\n",
    "        y_pred = model.predict(train_features)\n",
    "        label_pred = pred2label(y_pred)\n",
    "        \n",
    "        acc = accuracy_score(train_labels, label_pred)\n",
    "        prec = precision_score(train_labels,label_pred)\n",
    "\n",
    "        conf = confusion_matrix(train_labels, label_pred)\n",
    "        if(conf[0][0]+conf[1][0]):\n",
    "            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "        else:\n",
    "            sens = 0.0\n",
    "        if(conf[1][1]+conf[0][1]):\n",
    "            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "        else:\n",
    "            spec = 0.0\n",
    "        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "        else:\n",
    "            mcc= 0.0\n",
    "        fpr, tpr, thresholds = roc_curve(train_labels, y_pred)\n",
    "        auc = roc_auc_score(train_labels, y_pred)\n",
    "        \n",
    "        evaluations[\"Model\"].append(modelName)\n",
    "        evaluations[\"Fold\"].append(i)\n",
    "        evaluations[\"Train_Test\"].append(\"Train\")\n",
    "        evaluations[\"Accuracy\"].append(acc)\n",
    "        evaluations[\"Precision\"].append(prec)\n",
    "        evaluations[\"TPR\"].append(tpr)\n",
    "        evaluations[\"FPR\"].append(fpr)\n",
    "        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "        evaluations[\"AUC\"].append(auc)\n",
    "        evaluations[\"Sensitivity\"].append(sens)\n",
    "        evaluations[\"Specificity\"].append(spec)\n",
    "        evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Prediction and metrics for TEST dataset\n",
    "        ##################################################################################\n",
    "\n",
    "        y_pred = model.predict(test_features)\n",
    "        label_pred = pred2label(y_pred)\n",
    "        \n",
    "        acc = accuracy_score(test_labels, label_pred)\n",
    "        prec = precision_score(test_labels,label_pred)\n",
    "\n",
    "        conf = confusion_matrix(test_labels, label_pred)\n",
    "        if(conf[0][0]+conf[1][0]):\n",
    "            sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "        else:\n",
    "            sens = 0.0\n",
    "        if(conf[1][1]+conf[0][1]):\n",
    "            spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "        else:\n",
    "            spec = 0.0\n",
    "        if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "            mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "        else:\n",
    "            mcc= 0.0\n",
    "        fpr, tpr, thresholds = roc_curve(test_labels, y_pred)\n",
    "        auc = roc_auc_score(test_labels, y_pred)\n",
    "        \n",
    "        evaluations[\"Model\"].append(modelName)\n",
    "        evaluations[\"Fold\"].append(i)\n",
    "        evaluations[\"Train_Test\"].append(\"Test\")\n",
    "        evaluations[\"Accuracy\"].append(acc)\n",
    "        evaluations[\"Precision\"].append(prec)\n",
    "        evaluations[\"TPR\"].append(tpr)\n",
    "        evaluations[\"FPR\"].append(fpr)\n",
    "        evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "        evaluations[\"AUC\"].append(auc)\n",
    "        evaluations[\"Sensitivity\"].append(sens)\n",
    "        evaluations[\"Specificity\"].append(spec)\n",
    "        evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    i = i+1\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "################################################################################\n",
    "##### Dump evaluations to a file\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "pickle.dump(evaluations,\n",
    "            open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, \"all\")), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Parameters used only in this section\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 10\n",
    "expName = \"allModels_piRNA_generate\"\n",
    "outPath = \"Generated\"\n",
    "kmer_word2vec = 6\n",
    "\n",
    "modelNames = [\"DLNN_3\", \"DLNN_5\", \"DLNN_CORENup\", \"Dense_{}mer_word2vec\".format(kmer_word2vec), \"GlobalEmbed_RandomForest\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations_{}.pickle\".format(n_fold, \"all\")), \"rb\"))\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DLNN_3</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.883575</td>\n",
       "      <td>0.864483</td>\n",
       "      <td>[0.0, 0.0007836990595611285, 0.273510971786833...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.000784313725490196, 0.000784...</td>\n",
       "      <td>[1.9949371, 0.99493706, 0.94518834, 0.9449717,...</td>\n",
       "      <td>0.952408</td>\n",
       "      <td>0.904801</td>\n",
       "      <td>0.864483</td>\n",
       "      <td>0.768206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DLNN_3</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[0.0, 0.007042253521126761, 0.4295774647887324...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.007042253521126761, 0.007042...</td>\n",
       "      <td>[1.9974413, 0.9974413, 0.9562576, 0.95620745, ...</td>\n",
       "      <td>0.963202</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.732695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DLNN_5</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.889063</td>\n",
       "      <td>0.864270</td>\n",
       "      <td>[0.0, 0.0007836990595611285, 0.287617554858934...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.000784313725490196, 0.000784...</td>\n",
       "      <td>[1.9966415, 0.9966415, 0.96070135, 0.96040165,...</td>\n",
       "      <td>0.956865</td>\n",
       "      <td>0.917508</td>\n",
       "      <td>0.864270</td>\n",
       "      <td>0.779937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DLNN_5</td>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>[0.0, 0.007042253521126761, 0.3450704225352112...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.007042253521126761, 0.007042...</td>\n",
       "      <td>[1.9980617, 0.9980617, 0.97565526, 0.9737838, ...</td>\n",
       "      <td>0.959730</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.703962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DLNN_CORENup</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.923559</td>\n",
       "      <td>0.904869</td>\n",
       "      <td>[0.0, 0.0007836990595611285, 0.268025078369905...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.000784313725490196, 0.000784...</td>\n",
       "      <td>[1.9926932, 0.9926932, 0.9612205, 0.9612015, 0...</td>\n",
       "      <td>0.976330</td>\n",
       "      <td>0.944079</td>\n",
       "      <td>0.904869</td>\n",
       "      <td>0.848024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>DLNN_CORENup</td>\n",
       "      <td>9</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>[0.0, 0.0070921985815602835, 0.113475177304964...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0070921985815602835, 0.00709...</td>\n",
       "      <td>[1.9913423, 0.99134237, 0.9557005, 0.95422095,...</td>\n",
       "      <td>0.911674</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.663862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>Dense_6mer_word2vec</td>\n",
       "      <td>9</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.499804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0007830853563038371, 0.00078...</td>\n",
       "      <td>[0.0, 0.0007836990595611285, 0.005485893416927...</td>\n",
       "      <td>[1.4998891, 0.49988917, 0.4998879, 0.49988785,...</td>\n",
       "      <td>0.552720</td>\n",
       "      <td>0.499804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Dense_6mer_word2vec</td>\n",
       "      <td>9</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0070921985815602835, 0.00709...</td>\n",
       "      <td>[0.0, 0.0070921985815602835, 0.028368794326241...</td>\n",
       "      <td>[1.499889, 0.49988905, 0.49988744, 0.49988726,...</td>\n",
       "      <td>0.465268</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>GlobalEmbed_RandomForest</td>\n",
       "      <td>9</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>GlobalEmbed_RandomForest</td>\n",
       "      <td>9</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>[0.0, 0.45390070921985815, 1.0]</td>\n",
       "      <td>[0.0, 0.2907801418439716, 1.0]</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>0.564972</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.168712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Fold Train_Test  Accuracy  Precision  \\\n",
       "0                     DLNN_3     0      Train  0.883575   0.864483   \n",
       "1                     DLNN_3     0       Test  0.859155   0.800000   \n",
       "2                     DLNN_5     0      Train  0.889063   0.864270   \n",
       "3                     DLNN_5     0       Test  0.845070   0.788235   \n",
       "4               DLNN_CORENup     0      Train  0.923559   0.904869   \n",
       "..                       ...   ...        ...       ...        ...   \n",
       "95              DLNN_CORENup     9       Test  0.829787   0.872000   \n",
       "96       Dense_6mer_word2vec     9      Train  0.499804   0.000000   \n",
       "97       Dense_6mer_word2vec     9       Test  0.500000   0.000000   \n",
       "98  GlobalEmbed_RandomForest     9      Train  1.000000   1.000000   \n",
       "99  GlobalEmbed_RandomForest     9       Test  0.581560   0.609524   \n",
       "\n",
       "                                                  TPR  \\\n",
       "0   [0.0, 0.0007836990595611285, 0.273510971786833...   \n",
       "1   [0.0, 0.007042253521126761, 0.4295774647887324...   \n",
       "2   [0.0, 0.0007836990595611285, 0.287617554858934...   \n",
       "3   [0.0, 0.007042253521126761, 0.3450704225352112...   \n",
       "4   [0.0, 0.0007836990595611285, 0.268025078369905...   \n",
       "..                                                ...   \n",
       "95  [0.0, 0.0070921985815602835, 0.113475177304964...   \n",
       "96  [0.0, 0.0, 0.0, 0.0007830853563038371, 0.00078...   \n",
       "97  [0.0, 0.0, 0.0, 0.0070921985815602835, 0.00709...   \n",
       "98                                    [0.0, 1.0, 1.0]   \n",
       "99                    [0.0, 0.45390070921985815, 1.0]   \n",
       "\n",
       "                                                  FPR  \\\n",
       "0   [0.0, 0.0, 0.0, 0.000784313725490196, 0.000784...   \n",
       "1   [0.0, 0.0, 0.0, 0.007042253521126761, 0.007042...   \n",
       "2   [0.0, 0.0, 0.0, 0.000784313725490196, 0.000784...   \n",
       "3   [0.0, 0.0, 0.0, 0.007042253521126761, 0.007042...   \n",
       "4   [0.0, 0.0, 0.0, 0.000784313725490196, 0.000784...   \n",
       "..                                                ...   \n",
       "95  [0.0, 0.0, 0.0, 0.0070921985815602835, 0.00709...   \n",
       "96  [0.0, 0.0007836990595611285, 0.005485893416927...   \n",
       "97  [0.0, 0.0070921985815602835, 0.028368794326241...   \n",
       "98                                    [0.0, 0.0, 1.0]   \n",
       "99                     [0.0, 0.2907801418439716, 1.0]   \n",
       "\n",
       "                                   TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0   [1.9949371, 0.99493706, 0.94518834, 0.9449717,...  0.952408     0.904801   \n",
       "1   [1.9974413, 0.9974413, 0.9562576, 0.95620745, ...  0.963202     0.947368   \n",
       "2   [1.9966415, 0.9966415, 0.96070135, 0.96040165,...  0.956865     0.917508   \n",
       "3   [1.9980617, 0.9980617, 0.97565526, 0.9737838, ...  0.959730     0.929825   \n",
       "4   [1.9926932, 0.9926932, 0.9612205, 0.9612015, 0...  0.976330     0.944079   \n",
       "..                                                ...       ...          ...   \n",
       "95  [1.9913423, 0.99134237, 0.9557005, 0.95422095,...  0.911674     0.796178   \n",
       "96  [1.4998891, 0.49988917, 0.4998879, 0.49988785,...  0.552720     0.499804   \n",
       "97  [1.499889, 0.49988905, 0.49988744, 0.49988726,...  0.465268     0.500000   \n",
       "98                                          [2, 1, 0]  1.000000     1.000000   \n",
       "99                                          [2, 1, 0]  0.581560     0.564972   \n",
       "\n",
       "    Specificity       MCC  \n",
       "0      0.864483  0.768206  \n",
       "1      0.800000  0.732695  \n",
       "2      0.864270  0.779937  \n",
       "3      0.788235  0.703962  \n",
       "4      0.904869  0.848024  \n",
       "..          ...       ...  \n",
       "95     0.872000  0.663862  \n",
       "96     0.000000  0.000000  \n",
       "97     0.000000  0.000000  \n",
       "98     1.000000  1.000000  \n",
       "99     0.609524  0.168712  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "all_Train = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['Train'])]\n",
    "all_Test = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['Test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Available : \n",
      "['Accuracy', 'Precision', 'AUC', 'Sensitivity', 'Specificity', 'MCC']\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Decide on metric to visualize\n",
    "##################################################################################\n",
    "\n",
    "print(\"Metrics Available : \")\n",
    "print(list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DLNN_3',\n",
       " 'DLNN_5',\n",
       " 'DLNN_CORENup',\n",
       " 'Dense_6mer_word2vec',\n",
       " 'GlobalEmbed_RandomForest']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = list(np.unique(all_Train.index.get_level_values(0)))\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DLNN_3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.883597</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.910139</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>0.769479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DLNN_5</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.890417</td>\n",
       "      <td>0.875164</td>\n",
       "      <td>0.957069</td>\n",
       "      <td>0.907623</td>\n",
       "      <td>0.875164</td>\n",
       "      <td>0.781803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DLNN_CORENup</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.906858</td>\n",
       "      <td>0.976350</td>\n",
       "      <td>0.937780</td>\n",
       "      <td>0.906858</td>\n",
       "      <td>0.843335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dense_6mer_word2vec</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.499980</td>\n",
       "      <td>0.200078</td>\n",
       "      <td>0.525921</td>\n",
       "      <td>0.299902</td>\n",
       "      <td>0.200078</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GlobalEmbed_RandomForest</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision       AUC  \\\n",
       "Model                    Train_Test                                  \n",
       "DLNN_3                   Train       0.883597   0.861665  0.953684   \n",
       "DLNN_5                   Train       0.890417   0.875164  0.957069   \n",
       "DLNN_CORENup             Train       0.921026   0.906858  0.976350   \n",
       "Dense_6mer_word2vec      Train       0.499980   0.200078  0.525921   \n",
       "GlobalEmbed_RandomForest Train       1.000000   1.000000  1.000000   \n",
       "\n",
       "                                     Sensitivity  Specificity       MCC  \n",
       "Model                    Train_Test                                      \n",
       "DLNN_3                   Train          0.910139     0.861665  0.769479  \n",
       "DLNN_5                   Train          0.907623     0.875164  0.781803  \n",
       "DLNN_CORENup             Train          0.937780     0.906858  0.843335  \n",
       "Dense_6mer_word2vec      Train          0.299902     0.200078  0.000000  \n",
       "GlobalEmbed_RandomForest Train          1.000000     1.000000  1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter_df  = DLNN_Train[DLNN_Train.index.isin(a)]\n",
    "all_Train[all_Train.index.get_level_values('Model').isin(model_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Visualize with a multiple Bar chart\n",
    "##################################################################################\n",
    "\n",
    "x = np.arange(len(all_Train[metric_to_plot]))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,6))\n",
    "rects1 = ax.bar(x - (1.5*(width/2)), round(all_Train[metric_to_plot]*100, 3), width, label='Random Forest, Train')\n",
    "rects3 = ax.bar(x + (1.5*(width/2)), round(all_Test[metric_to_plot]*100, 3), width, label='Random Forest, Test')\n",
    "\n",
    "## Custom y-axis tick labels\n",
    "ax.set_ylabel(metric_to_plot)\n",
    "ax.set_ylim([max((math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, 0), \n",
    "            max((math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10, 0)])\n",
    "# ax.set_ylim([80, 105])\n",
    "\n",
    "## Custom x-axis tick labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_Train.index.get_level_values(0))\n",
    "# ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "#                         zip(DLNN_CORENup_Train.index.get_level_values(0),DLNN_CORENup_Train.index.get_level_values(1))],\n",
    "#                   rotation=30)\n",
    "# ax.set_xticklabels([a + \"_\" + b.split(\"_\")[1] for a, b in zip(RF_Train.index.get_level_values(0), RF_Train.index.get_level_values(1))],\n",
    "#                   rotation=30)\n",
    "\n",
    "\n",
    "ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\", \n",
    "                    ha='center', va='bottom', rotation=90)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Iteratively generate comparison plot using every metric\n",
    "##################################################################################\n",
    "\n",
    "for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "    x = np.arange(len(all_Train[metric_to_plot]))\n",
    "    width = 0.15\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(17,6))\n",
    "    rects1 = ax.bar(x - (1.5*(width/2)), round(all_Train[metric_to_plot]*100, 3), width, label='Random Forest, Train')\n",
    "    rects3 = ax.bar(x + (1.5*(width/2)), round(all_Test[metric_to_plot]*100, 3), width, label='Random Forest, Test')\n",
    "\n",
    "    ## Custom y-axis tick labels\n",
    "    ax.set_ylabel(metric_to_plot)\n",
    "    ax.set_ylim([max((math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, 0), \n",
    "                max((math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10, 0)])\n",
    "    # ax.set_ylim([80, 105])\n",
    "\n",
    "    ## Custom x-axis tick labels\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(all_Train.index.get_level_values(0))\n",
    "    # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "    #                         zip(DLNN_CORENup_Train.index.get_level_values(0),DLNN_CORENup_Train.index.get_level_values(1))],\n",
    "    #                   rotation=30)\n",
    "    # ax.set_xticklabels([a + \"_\" + b.split(\"_\")[1] for a, b in zip(RF_Train.index.get_level_values(0), RF_Train.index.get_level_values(1))],\n",
    "    #                   rotation=30)\n",
    "\n",
    "\n",
    "    ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\", \n",
    "                        ha='center', va='bottom', rotation=90)\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects3)\n",
    "    \n",
    "    plt.savefig(os.path.join(evalPath, \"{}_{}_Comparison\".format(metric_to_plot, modelNames[0].format(\"all\"))))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
